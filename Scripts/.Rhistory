Headers <- cbind(TimeFrame, Stations)
Headers <- cbind("Date", Stations)
Headers <- cbind("Date", Stations)
source("C:/Users/palemi/Documents/Github/DWRAT_DataScraping/Scripts/Downsizer_Processor.R", echo=TRUE)
View(Headers)
Headers = read.csv(file = here("InputData/Downsizer_Stations.csv"))
Headers = Headers %>% add_column("Date")
Downsizer = read.csv(file = here("InputData/2023.1.05.csv"))
Headers = read.csv(file = here("InputData/Downsizer_Stations.csv"))
Headers = Headers %>% add_column("Date")
View(Headers)
View(Headers)
source("C:/Users/palemi/Documents/Github/DWRAT_DataScraping/Scripts/Downsizer_Processor.R", echo=TRUE)
View(Headers)
Headers = read.csv(file = here("InputData/Downsizer_Stations.csv"))
View(Headers)
#Load libraries----
library(dplyr)
library(tidyverse)
library(here)
library(lubridate)
#Extract the Downsizer Headers----
#Import Downsizer_Headers.csv (long names)
Downsizer_Headers = read.csv(here("InputData/Downsizer_Headers.csv"), header = FALSE)
#Remove all forward slashes
Downsizer_Headers = gsub(pattern = "/", replacement = "", Downsizer_Headers)
Downsizer_Headers
#Load libraries----
library(dplyr)
library(tidyverse)
library(here)
library(lubridate)
#Extract the Downsizer Headers----
#Import Downsizer_Headers.csv (long names)
Downsizer_Headers = read.csv(here("InputData/Downsizer_Headers.csv"), header = FALSE)
#Remove all forward slashes
Downsizer_Headers = gsub(pattern = "/", replacement = "", Downsizer_Headers)
Downsizer_Headers
#Remove all substrings "\t"
Downsizer_Headers = gsub(pattern = "\t", replacement =  "", Downsizer_Headers)
Downsizer_Headers
#Remove all blank spaces
Downsizer_Headers = gsub(pattern = " ", replacement = "", Downsizer_Headers)
Downsizer_Headers
#Extract the Downsizer Headers----
#Import Downsizer_Headers.csv (long names)
Downsizer_Headers = read.csv(here("InputData/Downsizer_Headers.csv"), header = FALSE)
#Remove all forward slashes
Downsizer_Headers = gsub(pattern = "/", replacement = "", Downsizer_Headers)
Downsizer_Headers
#Remove all substrings "\t"
Downsizer_Headers = gsub(pattern = "\t", replacement =  "", Downsizer_Headers)
Downsizer_Headers
#Remove all blank spaces
Downsizer_Headers = gsub(pattern = " ", replacement = "", Downsizer_Headers)
Downsizer_Headers
#Rename the column to Stations
colnames(Downsizer_Headers) = "Stations"
#Load libraries----
library(dplyr)
library(tidyverse)
library(here)
library(lubridate)
#Extract the Downsizer Headers----
#Import Downsizer_Headers.csv (long names)
Downsizer_Headers = read.csv(here("InputData/Downsizer_Headers.csv"), header = FALSE)
#Remove all forward slashes
Downsizer_Headers = gsub(pattern = "/", replacement = "", Downsizer_Headers)
Downsizer_Headers
#Remove all substrings "\t"
Downsizer_Headers = gsub(pattern = "\t", replacement =  "", Downsizer_Headers)
Downsizer_Headers
#Remove all blank spaces
Downsizer_Headers = gsub(pattern = " ", replacement = "", Downsizer_Headers)
Downsizer_Headers
#Rename the column to Stations
colnames(Downsizer_Headers) = "Stations"
write.csv(Downsizer_Headers, here("InputData/Downsizer_Stations.csv"), row.names = FALSE)
colnames(Downsizer_Headers) = "Stations"
source("~/Github/DWRAT_DataScraping/Scripts/Downsizer_Headers_Extraction.R", echo=TRUE)
Downsizer_Headers
source("C:/Users/palemi/Documents/Github/DWRAT_DataScraping/Scripts/Downsizer_Processor.R")
## load packages
library(RSelenium)
library(tidyverse)
library(netstat)
library(here)
library(dplyr)
library(readr)
library(lubridate)
#InputData----
#Dates--adjust as needed
Stations <- read.csv(here("InputData/CIMIS_Stations.csv"))
StartDate = data.frame("December", "01", "2022", as.Date("2022-12-01"))
EndDate = data.frame("January", "04", "2023", as.Date("2023-01-04"))
colnames(StartDate) = c("month", "day", "year", "date")
colnames(EndDate) = c("month", "day", "year", "date")
ndays = seq(from = StartDate$date, to = EndDate$date, by = 'day')%>% length()
ndays
# Set up RSelenium ----
# Open a chrome browser session with RSelenium
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='108.0.5359.71',
port = free_port(),
)
eCaps <- list(
chromeOptions =
list(prefs = list(
"profile.default_content_settings.popups" = 0L,
"download.prompt_for_download" = FALSE,
"download.default_directory" = gsub(pattern = '/', replacement = '\\\\', x = here("WebData")) # download.dir
)
)
)
remDr <- rs_driver_object$client
#Create a list to hold CIMIS dataframes
DF_List <- list()
#Navigate to CIMIS----
for (i in 1:nrow(Stations)){
remDr$navigate(paste0("https://ipm.ucanr.edu/calludt.cgi/WXSTATIONDATA?MAP=&STN=", Stations$Alias[i]))
#Input Dates
StartMonth <- remDr$findElement(using = "name", value = "FROMMONTH")
StartMonth$sendKeysToElement(list(StartDate$month))
StartDay <- remDr$findElement(using = "name", value = "FROMDAY")
StartDay$sendKeysToElement(list(StartDate$day))
StartYear <- remDr$findElement(using = "name", value = "FROMYEAR")
StartYear$sendKeysToElement(list(StartDate$year))
EndMonth <- remDr$findElement(using = "name", value = "THRUMONTH")
EndMonth$sendKeysToElement(list(EndDate$month))
EndDay <-remDr$findElement(using = "name", value = "THRUDAY")
EndDay$sendKeysToElement(list(EndDate$day))
EndYear <-remDr$findElement(using = "name", value = "THRUYEAR")
EndYear$sendKeysToElement(list(EndDate$year))
#Use no backups
Backups <- remDr$findElement(using = "name", value = "NONE")
Backups$clickElement()
#Uncheck unnecessary checkboxes
Soil <- remDr$findElement(using = "name", value = "DT_SOIL")
Soil$clickElement()
Wind <- remDr$findElement(using = "name", value = "DT_WIND")
Wind$clickElement()
RH <- remDr$findElement(using = "name", value = "DT_RH")
RH$clickElement()
ET <- remDr$findElement(using = "name", value = "DT_ET")
ET$clickElement()
Solar <- remDr$findElement(using = "name", value = "DT_SOLAR")
Solar$clickElement()
#Metric Units
Metric <- remDr$findElement(using = "xpath", "//input[@value = 'M']")
Metric$clickElement()
#Comma delimited format
Comma <- remDr$findElement(using = "xpath", "//input[@value = 'T']")
Comma$clickElement()
#Retrieve Report
Report <-remDr$findElement(using = "xpath", "//input[@value = 'RETRIEVE DATA']")
Report$clickElement()
#Grab the Data
WeatherData <- remDr$findElement(using = "xpath", "//pre")
WeatherDataText <-WeatherData$getElementText() %>% unlist() %>% data.frame()
#Manipulate CIMIS Data After Download----
WeatherDataBody <- substring(WeatherDataText, 2551, nchar(WeatherDataText))
WeatherDataBody <-gsub("\\\n", " ", WeatherDataBody) #Remove \n from
WeatherDataBody <-gsub(" ", "", WeatherDataBody) #remove blank spaces
WeatherDataBody <- strsplit( WeatherDataBody, ",") %>% unlist %>% data.frame() #split by commas
#Force WeatherDataBody into a dataframe with 19 columns
WeatherDataBody <- split(WeatherDataBody,rep(1:ndays,each=19)) %>% data.frame %>% t() %>% data.frame()
#Drop the last 12 columns
WeatherDataBody <-select(WeatherDataBody, -c(X8:X19))
#Add column headers to WeatherDataBody
Headers <- c("Station","Date","Time","Precip","type","Tmax","Tmin")
colnames(WeatherDataBody) = Headers
#Drop Time and type columns
WeatherDataBody <- select(WeatherDataBody, -c("Time", "type"))
DF_List[[i]] <- WeatherDataBody
}
#Finalize CIMIS Data For Exportation To CSV----
#Name the individual RAWS dataframes in DF_List
names(DF_List) <- lapply(seq_along(DF_List),
function(i) names(DF_List)[[i]] = paste0("CIMIS_", Stations$Station[i]))
#Extract dataframes from DF_List
lapply(names(DF_List), function(i)
assign(x = i, value = DF_List[[i]], .GlobalEnv))
#Finalize CIMIS Sanel Valley 106
CIMIS_Sanel_Valley_106 = `CIMIS_Sanel Valley 106`
rm(`CIMIS_Sanel Valley 106`)
CIMIS_Sanel_Valley_106$Precip = NULL
#Finalize CIMIS Santa Rosa 83
CIMIS_Santa_Rosa_83 = `CIMIS_Santa Rosa 83`
rm(`CIMIS_Santa Rosa 83`)
CIMIS_Santa_Rosa_83$Precip = NULL
#Finalize CIMIS Windsor 103
CIMIS_Windsor_103 = `CIMIS_Windsor 103`
rm(`CIMIS_Windsor 103`)
CIMIS_Windsor_103$Tmin = NULL
CIMIS_Windsor_103$Tmax = NULL
#Finalize CIMIS Hopland 85 (just consists of -999)
CIMIS_Hopland_85 <- cbind.data.frame(seq(from = StartDate$date, to = EndDate$date, by = 'day'), rep(-999,ndays))
colnames(CIMIS_Hopland_85) <- c("Date", "Precipitation")
##Export Dataframes to CSVs----
write.csv(CIMIS_Windsor_103, here("ProcessedData/CIMIS_PRECIP12.csv"), row.names = FALSE)
write.csv(CIMIS_Sanel_Valley_106, here("ProcessedData/CIMIS_TEMP3.csv"), row.names = FALSE)
write.csv(CIMIS_Santa_Rosa_83, here("ProcessedData/CIMIS_TEMP4.csv"), row.names = FALSE)
write.csv(CIMIS_Hopland_85, here("ProcessedData/CIMIS_PRECIP6.csv"), row.names = FALSE)
# Set up RSelenium -------------------------------------------------------
## load packages
library(RSelenium)
library(rvest)
library(tidyverse)
library(netstat)
library(here)
library(dplyr)
library(readr)
##Set Default download folder----
eCaps <- list(
chromeOptions =
list(prefs = list(
"profile.default_content_settings.popups" = 0L,
"download.prompt_for_download" = FALSE,
"download.default_directory" = gsub(pattern = '/', replacement = '\\\\', x = here("WebData")) # download.dir
)
)
)
default_folder = here("WebData")
##Open a chrome browser session with RSelenium----
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='108.0.5359.71',
port = free_port(),
)
remDr <- rs_driver_object$client
#Input Data for both datasets----
#Define Dates
StartDate = data.frame("December", "01", "2022", as.Date("2022-12-01"))
EndDate = data.frame("January", "04", "2023", as.Date("2023-01-04"))
colnames(StartDate) = c("month", "day", "year", "date")
colnames(EndDate) = c("month", "day", "year", "date")
ndays = seq(from = StartDate$date, to = EndDate$date, by = 'day')%>% length()
ndays
#Precipitation Data----
##Input Locations File
PrecipitationFile <- gsub(pattern = "/", replacement = "\\\\", x = here("InputData/prism_rr_precip_stations.csv"))
##Navigate to PRISM Explorer webpage----
remDr <- rs_driver_object$client
URL <- "https://prism.oregonstate.edu/explorer/bulk.php"
remDr$navigate(URL)
##Fill out PRISM Explorer webpage----
#Select precipitation checkbox
# Precipitation <-remDr$findElement(using = "id", value = "cvar_ppt")
# Precipitation$clickElement()
#Deselect all other data settings checkboxes
MeanTemp <- remDr$findElement(using = "id", value = "cvar_tmean")
MeanTemp$clickElement()
#Select daily values
Daily <- remDr$findElement(using = "id", value = "tper_daily")
Daily$clickElement()
#Set the Starting Date
StartDay <- remDr$findElement(using = "id", value = "tper_daily_start_day")
StartDay$sendKeysToElement(list(StartDate$day))
StartMonth <- remDr$findElement(using = "id", value = "tper_daily_start_month")
StartMonth$sendKeysToElement(list(StartDate$month))
StartYear <- remDr$findElement(using = "id", value = "tper_daily_start_year")
StartYear$sendKeysToElement(list(StartDate$year))
#Set the Ending Date
EndDay <- remDr$findElement(using = "id", value = "tper_daily_end_day")
EndDay$sendKeysToElement(list(EndDate$day))
EndMonth <- remDr$findElement(using = "id", value = "tper_monthly_end_month")
EndMonth$sendKeysToElement(list(EndDate$month))
EndYear <- remDr$findElement(using = "id", value = "tper_daily_end_year")
EndYear$sendKeysToElement(list(EndDate$year))
#Select SI (metric) units
Units <- remDr$findElement(using = "id", value = "units_si")
Units$clickElement()
#Check Interpolate grid cell values
Grid <- remDr$findElement(using = "id", value = "loc_interp")
Grid$clickElement()
#Select Open Locations File
UploadBtn <- remDr$findElement(using = "id", value = "upload_locations")
#UploadBtn$sendKeysToElement(list(PrecipitationFile))
UploadBtn$sendKeysToElement(list("C:\\Users\\palemi\\Water Boards\\Supply and Demand Assessment - Documents\\DWRAT_DataScraping\\InputData\\prism_rr_precip_stations.csv"))
UploadBtn$clickElement()
#Click Prepare & Download Time Series
SubmitBtn <- remDr$findElement(using = "id", value = "submitdown_button")
SubmitBtn$clickElement()
#Temperature Data ----
#Import Temperature Stations
TempFile <- gsub(pattern = "/", replacement = "\\\\", x = here("InputData/temp_fill_stations.csv"))
##Navigate to PRISM Explorer webpage----
remDr <- rs_driver_object$client
URL <- "https://prism.oregonstate.edu/explorer/bulk.php"
remDr$navigate(URL)
#Deselect precipitation checkbox
Precipitation <-remDr$findElement(using = "id", value = "cvar_ppt")
Precipitation$clickElement()
#Select Temperature checkboxes
MinTemp <-remDr$findElement(using = "id", value = "cvar_tmin")
MinTemp$clickElement()
MaxTemp <- remDr$findElement(using = "id", value = "cvar_tmax")
MaxTemp$clickElement()
#Select daily values
Daily <- remDr$findElement(using = "id", value = "tper_daily")
Daily$clickElement()
#Set the Starting Date
StartDay <- remDr$findElement(using = "id", value = "tper_daily_start_day")
StartDay$sendKeysToElement(list(StartDate$day))
StartMonth <- remDr$findElement(using = "id", value = "tper_daily_start_month")
StartMonth$sendKeysToElement(list(StartDate$month))
StartYear <- remDr$findElement(using = "id", value = "tper_daily_start_year")
StartYear$sendKeysToElement(list(StartDate$year))
#Set the Ending Date
EndDay <- remDr$findElement(using = "id", value = "tper_daily_end_day")
EndDay$sendKeysToElement(list(EndDate$day))
EndMonth <- remDr$findElement(using = "id", value = "tper_monthly_end_month")
EndMonth$sendKeysToElement(list(EndDate$month))
EndYear <- remDr$findElement(using = "id", value = "tper_daily_end_year")
EndYear$sendKeysToElement(list(EndDate$year))
#Select SI (metric) units
Units <- remDr$findElement(using = "id", value = "units_si")
Units$clickElement()
#Check Interpolate grid cell values
Grid <- remDr$findElement(using = "id", value = "loc_interp")
Grid$clickElement()
#Select Open Locations File
UploadBtn <- remDr$findElement(using = "id", value = "upload_locations")
UploadBtn$sendKeysToElement(list(TempFile))
UploadBtn$clickElement()
#Click Prepare & Download Time Series
SubmitBtn <- remDr$findElement(using = "id", value = "submitdown_button")
SubmitBtn$clickElement()
#Set up RSelenium ----
## load packages ----
library(RSelenium)
library(rvest)
library(tidyverse)
library(netstat)
library(here)
library(dplyr)
library(readr)
##Set Default download folder ----
eCaps <- list(
chromeOptions =
list(prefs = list(
"profile.default_content_settings.popups" = 0L,
"download.prompt_for_download" = FALSE,
"download.default_directory" = gsub(pattern = '/', replacement = '\\\\', x = here("WebData")) # download.dir
)
)
)
default_folder = here("WebData")
## Open browser ----
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='108.0.5359.71',
port = free_port(),
)
remDr <- rs_driver_object$client
#Input Data----
#Import RAWS stations
Stations = read.csv("InputData/Raws_Stations.csv")
## load packages
library(RSelenium)
library(tidyverse)
library(netstat)
library(here)
library(dplyr)
library(readr)
library(lubridate)
#InputData----
#Dates--adjust as needed
Stations <- read.csv(here("InputData/CIMIS_Stations.csv"))
StartDate = data.frame("February", "01", "2023", as.Date("2023-02-01"))
EndDate = data.frame("March", "13", "2023", as.Date("2023-03-04"))
colnames(StartDate) = c("month", "day", "year", "date")
colnames(EndDate) = c("month", "day", "year", "date")
ndays = seq(from = StartDate$date, to = EndDate$date, by = 'day')%>% length()
ndays
# Set up RSelenium ----
# Open a chrome browser session with RSelenium
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='108.0.5359.71',
port = free_port(),
)
eCaps <- list(
chromeOptions =
list(prefs = list(
"profile.default_content_settings.popups" = 0L,
"download.prompt_for_download" = FALSE,
"download.default_directory" = gsub(pattern = '/', replacement = '\\\\', x = here("WebData")) # download.dir
)
)
)
remDr <- rs_driver_object$client
#Create a list to hold CIMIS dataframes
DF_List <- list()
#Navigate to CIMIS----
for (i in 1:nrow(Stations)){
#i=1
remDr$navigate(paste0("https://ipm.ucanr.edu/calludt.cgi/WXSTATIONDATA?MAP=&STN=", Stations$Alias[i]))
#Input Dates
StartMonth <- remDr$findElement(using = "name", value = "FROMMONTH")
StartMonth$sendKeysToElement(list(StartDate$month))
StartDay <- remDr$findElement(using = "name", value = "FROMDAY")
StartDay$sendKeysToElement(list(StartDate$day))
StartYear <- remDr$findElement(using = "name", value = "FROMYEAR")
StartYear$sendKeysToElement(list(StartDate$year))
EndMonth <- remDr$findElement(using = "name", value = "THRUMONTH")
EndMonth$sendKeysToElement(list(EndDate$month))
EndDay <-remDr$findElement(using = "name", value = "THRUDAY")
EndDay$sendKeysToElement(list(EndDate$day))
EndYear <-remDr$findElement(using = "name", value = "THRUYEAR")
EndYear$sendKeysToElement(list(EndDate$year))
#Use no backups
Backups <- remDr$findElement(using = "name", value = "NONE")
Backups$clickElement()
#Uncheck unnecessary checkboxes
Soil <- remDr$findElement(using = "name", value = "DT_SOIL")
Soil$clickElement()
Wind <- remDr$findElement(using = "name", value = "DT_WIND")
Wind$clickElement()
RH <- remDr$findElement(using = "name", value = "DT_RH")
RH$clickElement()
ET <- remDr$findElement(using = "name", value = "DT_ET")
ET$clickElement()
Solar <- remDr$findElement(using = "name", value = "DT_SOLAR")
Solar$clickElement()
#Metric Units
Metric <- remDr$findElement(using = "xpath", "//input[@value = 'M']")
Metric$clickElement()
#Comma delimited format
Comma <- remDr$findElement(using = "xpath", "//input[@value = 'T']")
Comma$clickElement()
#Retrieve Report
Report <-remDr$findElement(using = "xpath", "//input[@value = 'RETRIEVE DATA']")
Report$clickElement()
#Grab the Data
WeatherData <- remDr$findElement(using = "xpath", "//pre")
WeatherDataText <-WeatherData$getElementText() %>% unlist() %>% data.frame()
#Manipulate CIMIS Data After Download----
WeatherDataBody <- substring(WeatherDataText, 2551, nchar(WeatherDataText))
WeatherDataBody <-gsub("\\\n", " ", WeatherDataBody) #Remove \n from
WeatherDataBody <-gsub(" ", "", WeatherDataBody) #remove blank spaces
WeatherDataBody <- strsplit( WeatherDataBody, ",") %>% unlist %>% data.frame() #split by commas
#Force WeatherDataBody into a dataframe with 19 columns
WeatherDataBody <- split(WeatherDataBody,rep(1:(nrow(WeatherDataBody)/19),each=19)) %>% data.frame %>% t() %>% data.frame()
#Drop the last 12 columns
WeatherDataBody <-select(WeatherDataBody, -c(X8:X19))
#Add column headers to WeatherDataBody
Headers <- c("Station","Date","Time","Precip","type","Tmax","Tmin")
colnames(WeatherDataBody) = Headers
#Drop Time and type columns
WeatherDataBody <- select(WeatherDataBody, -c("Time", "type"))
DF_List[[i]] <- WeatherDataBody
}
i=1
remDr$navigate(paste0("https://ipm.ucanr.edu/calludt.cgi/WXSTATIONDATA?MAP=&STN=", Stations$Alias[i]))
remDr$open()
# Set up RSelenium -------------------------------------------------------
## load packages ----
library(RSelenium)
library(tidyverse)
library(netstat)
library(here)
library(dplyr)
library(readr)
# Import CNRFC Temperature stations----
CNRFC_Stations <- read.csv("InputData/CNRFC_Stations.csv")
# Set up RSelenium -------------------------------------------------------
## load packages ----
library(RSelenium)
library(tidyverse)
library(netstat)
library(here)
library(dplyr)
library(readr)
# Import CNRFC Temperature stations----
CNRFC_Stations <- read.csv("InputData/CNRFC_Stations.csv")
CNRFC_Stations <- read.csv("InputData/CNRFC_Stations.csv")
library(readr)
CNRFC_Stations <- read_csv("~/Github/DWRAT_DataScraping/InputData/CNRFC_Stations.csv")
View(CNRFC_Stations)
here()
here("InputData")
CNRFC_Stations <- read.csv(here("InputData/CNRFC_Stations.csv"))
##Set Default download folder ----
eCaps <- list(
chromeOptions =
list(prefs = list(
"profile.default_content_settings.popups" = 0L,
"download.prompt_for_download" = FALSE,
"download.default_directory" = gsub(pattern = '/', replacement = '\\\\', x = here("WebData")) # download.dir
)
)
)
default_folder <- eCaps$chromeOptions$prefs$download.default_directory
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='108.0.5359.71',
port = free_port(),
extraCapabilities = eCaps
)
remDr <- rs_driver_object$client
remDr$open()
binman::list_versions('chromedriver')
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='111.0.5563.64', #set to the version on your PC that most closely matches the chrome browser version
port = free_port(),
extraCapabilities = eCaps
)
remDr <- rs_driver_object$client
remDr$open()
