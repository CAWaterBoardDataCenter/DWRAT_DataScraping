##create separate dataframes for each Prism precipitation station----
#Create a vector consisting of each station's new name
PP_NewNames <- c("PP_PRECIP1", "PP_PRECIP2", "PP_PRECIP3", "PP_PRECIP4", "PP_PRECIP5",
"PP_PRECIP6", "PP_PRECIP7", "PP_PRECIP8", "PP_PRECIP9", "PP_PRECIP10",
"PP_PRECIP11", "PP_PRECIP12", "PP_PRECIP13", "PP_PRECIP14", "PP_PRECIP15")
PP_OldNames <- unique(PP$Name) #vector of unique Prism station names
#Replace old Prism station names with new names
PP$Name <- PP_NewNames[match(PP$Name,PP_OldNames, nomatch = 0)]
#Extract each station as a separate dataframe
for (i in unique(PP$Name)) {
assign(i, PP %>% filter (Name == i), envir = .GlobalEnv)
}
#Import DAT stuff
DAT_File <- read.delim(here("InputData/data_update_to_11.30.2022.txt"), sep = "\t")
DAT_Fields <- read.csv(here("InputData/DAT_Fields.csv"))
View(DAT_Fields)
View(DAT_File)
View(DAT_File)
#Set DAT_File column names
colnames(DAT_File) <- colnames(DAT_Fields)
#Whittle the DAT_File to a subset corresponding to our timeframe of interest, "DAT_Shell"----
#Add a Timestep column
DAT_File$TimeStep <- make_date(year = DAT_File$Year,
month = DAT_File$month,
day = DAT_File$day)
#Filter to the timeframe of interest
#Set the start date by grabbing the first day of the current month
#Start_Date <- lubridate::floor_date(Sys.Date(), unit = "month")
Start_Date <- as.Date("2023-01-11")
View(StartDate)
#The end date is the current date + 5 days in the future; we grab 6 days of forecast data from CNRFC
End_Date <- Sys.Date() + 5
View(EndDates)
View(EndDate)
View(EndDate)
#The end date is the current date + 5 days in the future; we grab 6 days of forecast data from CNRFC
End_Date <- Sys.Date() + 5
View(EndDate)
End_Date
View(EndDate)
DAT_Shell <- subset(DAT_File, TimeStep >= '2023-01-11' & TimeStep <= "2023-03-25") #Adjust as needed
DAT_Shell
View(DAT_Shell)
#Set TimeStep as the 7th column in DAT_Shell
DAT_Shell <- DAT_Shell %>% relocate(TimeStep, .after = s)
#Set all the DAT_Shell temperature and precipitation fields to blank
for (i in 1:length(DAT_Shell)){
if (colnames(DAT_Shell[i]) %>% str_detect("PREC")){
DAT_Shell[i] = ""
} else if (colnames(DAT_Shell[i]) %>% str_detect("TM")){
DAT_Shell[i] = ""
}else {
DAT_Shell[i] = DAT_Shell[i]
}
}
CIMIS_Processed
View(CIMIS_Processed)
# Import CNRFC Temperature stations----
CNRFC_Stations <- read.csv(here("InputData/CNRFC_Stations.csv"))
##Set Default download folder ----
eCaps <- list(
chromeOptions =
list(prefs = list(
"profile.default_content_settings.popups" = 0L,
"download.prompt_for_download" = FALSE,
"download.default_directory" = gsub(pattern = '/', replacement = '\\\\', x = here("WebData")) # download.dir
)
)
)
default_folder <- eCaps$chromeOptions$prefs$download.default_directory
#
## Find active versions of chrome on PC ----
binman::list_versions('chromedriver')
## Open a chrome browser session with RSelenium ----
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='111.0.5563.64', #set to the version on your PC that most closely matches the chrome browser version
port = free_port(),
extraCapabilities = eCaps
)
remDr <- rs_driver_object$client
remDr$open()
#Navigate to CNRFC website
for (i in 1:nrow(CNRFC_Stations)){
CNRFC <- paste0("https://www.cnrfc.noaa.gov/temperaturePlots_hc.php?id=", CNRFC_Stations$TempStation[i])
remDr$navigate(CNRFC)
#Select Chart Menu
ChartMenu <- remDr$findElement(using = "xpath", "//button[@aria-label = 'View chart menu']")
ChartMenu$clickElement()
#Download as CSV
CSVDownload <- remDr$findElement(using = "xpath", "//ul//li[contains(., 'CSV')]")
CSVDownload$clickElement()
}
#Work in progess ----
#Combining CNRFC data with CIMIS data
CNRFC_precip_data <- read.csv(here("InputData/CNRFC_precip_data.csv"))
library(here)
library(dplyr)
library(tidyr)
library(tidyverse)
library(lubridate)
#PRISM Precipitation Data Manipulation----
#Import PRISM_Precipitation.csv by skipping first 10 rows
ndays = 68
PP <- read.csv(here("WebData/PRISM_Precipitation.csv"), skip = 10, header = T)
names(PP)[1] = "Station"
names(PP)[6] = "ppt"
#Remove unnecessary columns
PP = select(PP, c("Station", "Date", "ppt"))
#Pivot PP so that each station becomes a separate column
PP <- pivot_wider(PP, id_cols = Date, names_from = Station, values_from = ppt)
##create separate dataframes for each Prism precipitation station----
#Create a vector consisting of each station's new name
PP_NewNames <- c("Date", "PP_PRECIP1", "PP_PRECIP2", "PP_PRECIP3", "PP_PRECIP4", "PP_PRECIP5",
"PP_PRECIP6", "PP_PRECIP7", "PP_PRECIP8", "PP_PRECIP9", "PP_PRECIP10",
"PP_PRECIP11", "PP_PRECIP12", "PP_PRECIP13", "PP_PRECIP14", "PP_PRECIP15")
PP_OldNames <- unique(PP) #vector of unique Prism station names
colnames(PP) = PP_NewNames
#Export PP to CSV
write.csv(here("WebData/PRISM_Precipitation.csv", row.names = FALSE))
View(PP)
View(PP_OldNames)
#Export PP to CSV
write.csv(PP, here("WebData/PRISM_Precipitation.csv", row.names = FALSE))

