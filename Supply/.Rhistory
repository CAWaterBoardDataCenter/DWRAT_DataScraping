last(chrome_driver_versions)
str_subset(string = last(chrome_driver_versions))
chrome_driver_current <- chrome_browser_version %>%
magrittr::extract(!is.na(.)) %>%
str_replace_all(pattern = "\\.", replacement = "\\\\.") %>%
paste0("^", .) %>%
str_subset(string = last(chrome_driver_versions))
#SCRIPT LAST UPDATED:
#BY: Payman Alemi
#ON: 7/12/2023
# Load packages
library(tidyverse)
library(RSelenium)
library(netstat)
library(here)
library(binman)
# Define Date Range
# StartDate <- as.Date("2023-04-01")
# EndDate <- as.Date("2023-05-21")
# Set up RSelenium----
##Set Default download folder----
eCaps <- list(
chromeOptions = list(
prefs = list(
"profile.default_content_settings.popups" = 0L,
"download.prompt_for_download" = FALSE,
"download.default_directory" = gsub(pattern = '/', replacement = '\\\\', x = here("WebData")) # download.dir
)
)
)
default_folder <- eCaps$chromeOptions$prefs$download.default_directory
## Download latest Chrome drivers---
temp <- wdman::chrome()
temp$stop()
## Set version of Chrome----
### Get current version of chrome browser----
chrome_browser_version <- system2(
command = "wmic",
args = 'datafile where name="C:\\\\Program Files (x86)\\\\Google\\\\Chrome\\\\Application\\\\chrome.exe" get Version /value',
stdout = TRUE,
stderr = TRUE
) %>%
str_extract(pattern = "(?<=Version=)(\\d+\\.){3}")
if (sum(!is.na(chrome_browser_version)) == 0) {
chrome_browser_version <- system2(
command = "wmic",
args = 'datafile where name="C:\\\\Program Files\\\\Google\\\\Chrome\\\\Application\\\\chrome.exe" get Version /value',
stdout = TRUE,
stderr = TRUE
) %>%
str_extract(pattern = "(?<=Version=)(\\d+\\.){3}")
}
### List the versions of chromedriver on this PC
chrome_driver_versions <- list_versions("chromedriver")
### Match drivers to version----
chrome_driver_current <- chrome_browser_version %>%
magrittr::extract(!is.na(.)) %>%
str_replace_all(pattern = "\\.", replacement = "\\\\.") %>%
paste0("^", .) %>%
str_subset(string = last(chrome_driver_versions)) %>%
as.numeric_version() %>%
max() %>%
as.character()
chrome_driver_dir <- paste0(app_dir("chromedriver", FALSE),
'/win32/',
chrome_driver_current)
if ('LICENSE.chromedriver' %in% list.files(chrome_driver_dir)) {
file.remove(
paste0(chrome_driver_dir, '/', 'LICENSE.chromedriver')
)
}
rs_driver_object <-rsDriver(
browser = 'chrome',
check = TRUE,
chromever = chrome_driver_current, #set to the version on your PC that most closely matches the chrome browser version
port = free_port(),
extraCapabilities = eCaps
)
Sys.sleep(1)
remDr <- rs_driver_object$client
source(here("Scripts/Downsizer_Processor.R"))
source(here("Scripts/Downsizer_Processor.R"))
library(tidyverse)
library(RSelenium)
library(netstat)
library(lubridate)
library(here)
library(tinytex)
library(KeyboardSimulator)
source(here("Scripts/Downsizer_Processor.R"))
source(here("Scripts/Downsizer_Processor.R"))
#Install libraries----
#Uncomment the lines below if you haven't installed these packages yet
# install.packages("dplyr")
# install.packages("tidyverse")
# install.packages("tidyr")
# install.packages("here")
# install.packages("lubridate")
#Load libraries----
library(dplyr)
library(tidyverse)
library(tidyr)
library(here)
library(lubridate)
#Import Downsizer Data----
# Get the file name (it will be the latest CSV file that starts with "Downsizer")
downsizerCSVname <- list.files() %>% str_subset("^Downsizer.+\\.csv$") %>% tail(1)
list.files()
getwd()
downsizerCSVname <- list.files("WebData") %>% str_subset("^Downsizer.+\\.csv$") %>% tail(1)
#Install libraries----
#Uncomment the lines below if you haven't installed these packages yet
# install.packages("dplyr")
# install.packages("tidyverse")
# install.packages("tidyr")
# install.packages("here")
# install.packages("lubridate")
#Load libraries----
library(dplyr)
library(tidyverse)
library(tidyr)
library(here)
library(lubridate)
#Import Downsizer Data----
# Get the file name (it will be the latest CSV file that starts with "Downsizer")
downsizerCSVname <- list.files("WebData") %>% str_subset("^Downsizer.+\\.csv$") %>% tail(1)
# Error Check
stopifnot(length(downsizerCSVname) == 1)
Downsizer_Original = read.csv(file = downsizerCSVname)
downsizerCSVname <- list.files("WebData", full.names = TRUE) %>% str_subset("^Downsizer.+\\.csv$") %>% tail(1)
list.files("WebData", full.names = TRUE)
downsizerCSVname <- list.files("WebData", full.names = T) %>%
str_subset("^WebData/Downsizer.+\\.csv$") %>% tail(1)
#Install libraries----
#Uncomment the lines below if you haven't installed these packages yet
# install.packages("dplyr")
# install.packages("tidyverse")
# install.packages("tidyr")
# install.packages("here")
# install.packages("lubridate")
#Load libraries----
library(dplyr)
library(tidyverse)
library(tidyr)
library(here)
library(lubridate)
#Import Downsizer Data----
# Get the file name (it will be the latest CSV file that starts with "Downsizer")
downsizerCSVname <- list.files("WebData", full.names = T) %>%
str_subset("^WebData/Downsizer.+\\.csv$") %>% tail(1)
# Error Check
stopifnot(length(downsizerCSVname) == 1)
Downsizer_Original = read.csv(file = downsizerCSVname)
Headers = read.csv(file = here("InputData/Downsizer_Stations.csv"))
#Account for timeframe of interest----
# StartDate = data.frame("April", "1", "2023", as.Date("2023-04-01"))
# EndDate = data.frame("May", "23", "2023", as.Date("2023-05-23"))
# colnames(StartDate) = c("month", "day", "year", "date")
# colnames(EndDate) = c("month", "day", "year", "date")
# ndays = seq(from = StartDate$date, to = EndDate$date, by = 'day') %>% length()
# ndays
# TimeFrame = seq(from = StartDate$date, to = EndDate$date, by = 'day')
#Extract the weather data from Downsizer_Original----
#Drop the first 42 rows of Downsizer
Downsizer = tail(Downsizer_Original, nrow(Downsizer_Original)-42) %>%data.frame()
colnames(Downsizer) = "Downsizer"
#Format the Downsizer dataframe to match the PRMS_Update DAT file----
##Calculate the number of columns after splitting the 1st column by the space delimiter----
ncols <- max(stringr::str_count(Downsizer$Downsizer))
ncols #creates 252 columns, but only the first 36 have content
colmn <- paste0("Col", 1:ncols) #creates a set of 252 columns named Col1, Col2, ....
colmn
##Split Downsizer into 253 columns by using spaces as delimiters----
Downsizer_Processed <-
tidyr::separate(
data = Downsizer,
col = Downsizer,
sep = " ",
into = colmn,
remove = FALSE
)
##Delete extra columns and apply column names----
Downsizer_Processed[38:253] = NULL
Downsizer_Processed[5:7] = NULL
Downsizer_Processed[1] = NULL
#Fill in the column names of Downsizer_Processed
colnames(Downsizer_Processed) = colnames(Headers)
colnames(Downsizer_Processed)
#Remove all NA columns from Downsizer_Processed
Downsizer_Processed <- select(Downsizer_Processed, -c(starts_with("NA")))
colnames(Downsizer_Processed)
##Rearrange Downsizer_Processed columns in proper order----
col_order <- c('Year', 'Month', 'Day', 'DOWNSIZER_PRECIP1', 'DOWNSIZER_PRECIP2',
'DOWNSIZER_PRECIP3', 'DOWNSIZER_PRECIP5', 'DOWNSIZER_PRECIP8', 'DOWNSIZER_PRECIP10',
'DOWNSIZER_PRECIP11', 'DOWNSIZER_PRECIP13','DOWNSIZER_PRECIP14', 'DOWNSIZER_PRECIP15',
'DOWNSIZER_TMAX1', 'DOWNSIZER_TMAX2', 'DOWNSIZER_TMAX6', 'DOWNSIZER_TMIN1', 'DOWNSIZER_TMIN2',
'DOWNSIZER_TMIN6')
Downsizer_Processed <- Downsizer_Processed[,col_order]
#BEFORE THIS STEP: Run PRISM_Processor.R, CNRFC_Scraper.R, & CNRFC_Processor.R----
#Replace missing values with PRISM data
#Works only if columns are same in number and order; column names don't need to match
Prism_Processed = read.csv(here("ProcessedData/Prism_Processed.csv"))
#Change date format of Downsizer data to match PRISM
Downsizer_Processed <- Downsizer_Processed %>%
unite(col = "Date", Year, Month, Day, sep = "-") %>%
mutate(Date = as.Date(Date))
#Create PRISM df to replace missing values
PRISM_cols <- Prism_Processed[,c('Date', 'PP_PRECIP1', 'PP_PRECIP2',
'PP_PRECIP3', 'PP_PRECIP5', 'PP_PRECIP8', 'PP_PRECIP10',
'PP_PRECIP11', 'PP_PRECIP13','PP_PRECIP14', 'PP_PRECIP15',
'PT_TMAX1', 'PT_TMAX2', 'PT_TMAX6', 'PT_TMIN1', 'PT_TMIN2',
'PT_TMIN6')]
#Change -999.0 values to -999
for (i in 2:17) {
Downsizer_Processed[, i] <- gsub("-999.0", "-999", Downsizer_Processed[, i])
}
#Replace -999 values with PRISM data
Downsizer_Processed[Downsizer_Processed == -999] <- PRISM_cols[Downsizer_Processed == -999]
#Combining Downsizer data with CNRFC data
CNRFC_Processed <- read.csv(here("ProcessedData/CNRFC_Processed.csv"))
CNRFC_cols <- CNRFC_Processed[,c("Date","PRECIP1_UKAC1","PRECIP2_LAMC1","PRECIP3_UKAC1","PRECIP5_UKAC1",
"PRECIP8_CDLC1","PRECIP10_HEAC1","PRECIP11_RMKC1","PRECIP13_GUEC1",
"PRECIP14_LSEC1","PRECIP15_GUEC1","TMAX1_HEAC1","TMAX2_UKAC1",
"TMAX6_LAMC1","TMIN1_HEAC1","TMIN2_UKAC1","TMIN6_LAMC1")]
#Rename CNRFC Columns to match Downsizer names to bind the datasets
col_order <- colnames(Downsizer_Processed)
colnames(CNRFC_cols) = col_order
#rbind() put scraped data first, CNRFC data second
Downsizer_Processed <- rbind(Downsizer_Processed,CNRFC_cols)
#Write CSV to ProcessedData Folder----
write.csv(Downsizer_Processed, here("ProcessedData/Downsizer_Processed.csv"), row.names = FALSE)
source(here("Scripts/DAT_Shell_Generation.R")) #Ignore the warning message:In eval(e, x, parent.frame()) :...
#install.packages ("tinytex")
# load packages -----------------------------------------------------------
library(tidyverse)
library(RSelenium)
library(netstat)
library(lubridate)
library(here)
library(tinytex)
library(KeyboardSimulator)
# RUNS SCRAPING & PROCESSING SCRIPTS IN ORDER TO GENERATE FINAL DAT FILE
# BEFORE running, download Downsizer data
# set start and end dates -------------------------------------------------
## Set start date----
StartDate <- as.Date("2023-05-08") # 1-2 months before previous end date
#Serves as the start date for the observed data forecast and the DAT_Shell
# Extract Day, Month, and Year from StartDate; functions require lubridate package
StartDay <- day(StartDate)
StartMonth <- month(StartDate)
StartYear <- year(StartDate)
StartDate <- data.frame(date = StartDate, day = StartDay, month = StartMonth, year = StartYear)
print(StartDate)
## set end date----
EndDate <- Sys.Date() - 1 # set to yesterday's date; serves as the end date for the observed data range
EndDay <- day(EndDate)
EndMonth <- month(EndDate)
EndYear <- year(EndDate)
EndDate <- data.frame(date = EndDate, day = EndDay, month = EndMonth, year = EndYear)
print(EndDate)
TimeFrame = seq(from = StartDate$date, to = EndDate$date, by = 'day') #Timeframe is necessary for Downsizer_Processor.R
End_Date <- Sys.Date() + 5 # forecast end date for DAT_Shell_Generation.R
# generate PRMS model input -----------------------------------------------
source(here("Scripts/Downsizer_Assistant_Noninteractive.R"))
source(here("Scripts/PRISM_Scraper.R"))
source(here("Scripts/PRISM_Processor.R"))
source(here("Scripts/CNRFC_Scraper.R"))
source(here("Scripts/CNRFC_RR_Processor.R"))
# change input file name for Downsizer data; you need to run Downsizer and
# move the Downsizer file to the WebData folder prior to running Downsizer_Processor.R
# Downsizer filename should match the filename given by Downsizer_Processor.R
source(here("Scripts/Downsizer_Processor.R")) #Ignore the warning message: Expected 252 pieces...
source(here("Scripts/RAWS_Scraper.R"))
source(here("Scripts/CIMIS_Scraper.R"))
source(here("Scripts/DAT_Shell_Generation.R")) #Ignore the warning message:In eval(e, x, parent.frame()) :...
# change output file name for DAT File
source(here("Scripts/DAT_File_Manipulation.R"))
# generate SRP model input ------------------------------------------------
source(here("Scripts/CNRFC_SRP_Processor.R"))
source(here("Scripts/PRISM_SRP_Processor.R"))
git add .
source(here("Scripts/PRISM_Scraper.R"))
library(tidyverse)
library(RSelenium)
library(netstat)
library(lubridate)
library(here)
library(tinytex)
library(KeyboardSimulator)
StartDate <- as.Date("2023-05-08") # 1-2 months before previous end date
#Serves as the start date for the observed data forecast and the DAT_Shell
# Extract Day, Month, and Year from StartDate; functions require lubridate package
StartDay <- day(StartDate)
StartMonth <- month(StartDate)
StartYear <- year(StartDate)
StartDate <- data.frame(date = StartDate, day = StartDay, month = StartMonth, year = StartYear)
print(StartDate)
## set end date----
EndDate <- Sys.Date() - 1 # set to yesterday's date; serves as the end date for the observed data range
EndDay <- day(EndDate)
EndMonth <- month(EndDate)
EndYear <- year(EndDate)
EndDate <- data.frame(date = EndDate, day = EndDay, month = EndMonth, year = EndYear)
print(EndDate)
TimeFrame = seq(from = StartDate$date, to = EndDate$date, by = 'day') #Timeframe is necessary for Downsizer_Processor.R
End_Date <- Sys.Date() + 5 # forecast end date for DAT_Shell_Generation.R
source(here("Scripts/PRISM_Scraper.R"))
source(here("Scripts/Downsizer_Processor.R"))
source(here("Scripts/Downsizer_Processor.R"))
StartDate <- as.Date("2023-01-01") # 1-2 months before previous end date
#Serves as the start date for the observed data forecast and the DAT_Shell
# Extract Day, Month, and Year from StartDate; functions require lubridate package
StartDay <- day(StartDate)
StartMonth <- month(StartDate)
StartYear <- year(StartDate)
StartDate <- data.frame(date = StartDate, day = StartDay, month = StartMonth, year = StartYear)
print(StartDate)
## set end date----
EndDate <- Sys.Date() - 1 # set to yesterday's date; serves as the end date for the observed data range
EndDay <- day(EndDate)
EndMonth <- month(EndDate)
EndYear <- year(EndDate)
EndDate <- data.frame(date = EndDate, day = EndDay, month = EndMonth, year = EndYear)
print(EndDate)
TimeFrame = seq(from = StartDate$date, to = EndDate$date, by = 'day') #Timeframe is necessary for Downsizer_Processor.R
End_Date <- Sys.Date() + 5 # forecast end date for DAT_Shell_Generation.R
source(here("Scripts/Downsizer_Processor.R"))
#install.packages ("tinytex")
# load packages -----------------------------------------------------------
library(tidyverse)
library(RSelenium)
library(netstat)
library(lubridate)
library(here)
library(tinytex)
library(KeyboardSimulator)
# RUNS SCRAPING & PROCESSING SCRIPTS IN ORDER TO GENERATE FINAL DAT FILE
# BEFORE running, download Downsizer data
# set start and end dates -------------------------------------------------
## Set start date----
StartDate <- as.Date("2023-01-01") # 1-2 months before previous end date
#Serves as the start date for the observed data forecast and the DAT_Shell
# Extract Day, Month, and Year from StartDate; functions require lubridate package
StartDay <- day(StartDate)
StartMonth <- month(StartDate)
StartYear <- year(StartDate)
StartDate <- data.frame(date = StartDate, day = StartDay, month = StartMonth, year = StartYear)
print(StartDate)
## set end date----
EndDate <- Sys.Date() - 1 # set to yesterday's date; serves as the end date for the observed data range
EndDay <- day(EndDate)
EndMonth <- month(EndDate)
EndYear <- year(EndDate)
EndDate <- data.frame(date = EndDate, day = EndDay, month = EndMonth, year = EndYear)
print(EndDate)
TimeFrame = seq(from = StartDate$date, to = EndDate$date, by = 'day') #Timeframe is necessary for Downsizer_Processor.R
End_Date <- Sys.Date() + 5 # forecast end date for DAT_Shell_Generation.R
#Install libraries----
#Uncomment the lines below if you haven't installed these packages yet
# install.packages("dplyr")
# install.packages("tidyverse")
# install.packages("tidyr")
# install.packages("here")
# install.packages("lubridate")
#Load libraries----
library(dplyr)
library(tidyverse)
library(tidyr)
library(here)
library(lubridate)
#Import Downsizer Data----
# Get the file name (it will be the latest CSV file that starts with "Downsizer")
downsizerCSVname <- list.files("WebData", full.names = T) %>%
str_subset("^WebData/Downsizer.+\\.csv$") %>% tail(1)
# Error Check
stopifnot(length(downsizerCSVname) == 1)
Downsizer_Original = read.csv(file = downsizerCSVname)
Headers = read.csv(file = here("InputData/Downsizer_Stations.csv"))
Downsizer = tail(Downsizer_Original, nrow(Downsizer_Original)-42) %>%data.frame()
colnames(Downsizer) = "Downsizer"
#Format the Downsizer dataframe to match the PRMS_Update DAT file----
##Calculate the number of columns after splitting the 1st column by the space delimiter----
ncols <- max(stringr::str_count(Downsizer$Downsizer))
ncols #creates 252 columns, but only the first 36 have content
colmn <- paste0("Col", 1:ncols) #creates a set of 252 columns named Col1, Col2, ....
colmn
##Split Downsizer into 253 columns by using spaces as delimiters----
Downsizer_Processed <-
tidyr::separate(
data = Downsizer,
col = Downsizer,
sep = " ",
into = colmn,
remove = FALSE
)
##Delete extra columns and apply column names----
Downsizer_Processed[38:253] = NULL
Downsizer_Processed[5:7] = NULL
Downsizer_Processed[1] = NULL
#Fill in the column names of Downsizer_Processed
colnames(Downsizer_Processed) = colnames(Headers)
colnames(Downsizer_Processed)
#Remove all NA columns from Downsizer_Processed
Downsizer_Processed <- select(Downsizer_Processed, -c(starts_with("NA")))
colnames(Downsizer_Processed)
##Rearrange Downsizer_Processed columns in proper order----
col_order <- c('Year', 'Month', 'Day', 'DOWNSIZER_PRECIP1', 'DOWNSIZER_PRECIP2',
'DOWNSIZER_PRECIP3', 'DOWNSIZER_PRECIP5', 'DOWNSIZER_PRECIP8', 'DOWNSIZER_PRECIP10',
'DOWNSIZER_PRECIP11', 'DOWNSIZER_PRECIP13','DOWNSIZER_PRECIP14', 'DOWNSIZER_PRECIP15',
'DOWNSIZER_TMAX1', 'DOWNSIZER_TMAX2', 'DOWNSIZER_TMAX6', 'DOWNSIZER_TMIN1', 'DOWNSIZER_TMIN2',
'DOWNSIZER_TMIN6')
Downsizer_Processed <- Downsizer_Processed[,col_order]
#BEFORE THIS STEP: Run PRISM_Processor.R, CNRFC_Scraper.R, & CNRFC_Processor.R----
#Replace missing values with PRISM data
#Works only if columns are same in number and order; column names don't need to match
Prism_Processed = read.csv(here("ProcessedData/Prism_Processed.csv"))
#Change date format of Downsizer data to match PRISM
Downsizer_Processed <- Downsizer_Processed %>%
unite(col = "Date", Year, Month, Day, sep = "-") %>%
mutate(Date = as.Date(Date))
#Create PRISM df to replace missing values
PRISM_cols <- Prism_Processed[,c('Date', 'PP_PRECIP1', 'PP_PRECIP2',
'PP_PRECIP3', 'PP_PRECIP5', 'PP_PRECIP8', 'PP_PRECIP10',
'PP_PRECIP11', 'PP_PRECIP13','PP_PRECIP14', 'PP_PRECIP15',
'PT_TMAX1', 'PT_TMAX2', 'PT_TMAX6', 'PT_TMIN1', 'PT_TMIN2',
'PT_TMIN6')]
#Change -999.0 values to -999
for (i in 2:17) {
Downsizer_Processed[, i] <- gsub("-999.0", "-999", Downsizer_Processed[, i])
}
#Replace -999 values with PRISM data
Downsizer_Processed[Downsizer_Processed == -999] <- PRISM_cols[Downsizer_Processed == -999]
#Combining Downsizer data with CNRFC data
CNRFC_Processed <- read.csv(here("ProcessedData/CNRFC_Processed.csv"))
CNRFC_cols <- CNRFC_Processed[,c("Date","PRECIP1_UKAC1","PRECIP2_LAMC1","PRECIP3_UKAC1","PRECIP5_UKAC1",
"PRECIP8_CDLC1","PRECIP10_HEAC1","PRECIP11_RMKC1","PRECIP13_GUEC1",
"PRECIP14_LSEC1","PRECIP15_GUEC1","TMAX1_HEAC1","TMAX2_UKAC1",
"TMAX6_LAMC1","TMIN1_HEAC1","TMIN2_UKAC1","TMIN6_LAMC1")]
#Rename CNRFC Columns to match Downsizer names to bind the datasets
col_order <- colnames(Downsizer_Processed)
colnames(CNRFC_cols) = col_order
#rbind() put scraped data first, CNRFC data second
Downsizer_Processed <- rbind(Downsizer_Processed,CNRFC_cols)
#Write CSV to ProcessedData Folder----
write.csv(Downsizer_Processed, here("ProcessedData/Downsizer_Processed.csv"), row.names = FALSE)
View(Downsizer_Processed)
downsizerCSVname <- list.files("WebData", full.names = T) %>%
str_subset("^WebData/Downsizer.+\\.csv$") %>% tail(1)
#Install libraries----
#Uncomment the lines below if you haven't installed these packages yet
# install.packages("dplyr")
# install.packages("tidyverse")
# install.packages("tidyr")
# install.packages("here")
# install.packages("lubridate")
#Load libraries----
library(dplyr)
library(tidyverse)
library(tidyr)
library(here)
library(lubridate)
#Import Downsizer Data----
# Get the file name (it will be the latest CSV file that starts with "Downsizer")
downsizerCSVname <- list.files("WebData", full.names = T) %>%
str_subset("^WebData/Downsizer.+\\.csv$") %>% tail(1)
# Error Check
stopifnot(length(downsizerCSVname) == 1)
Downsizer_Original = read.csv(file = downsizerCSVname)
Headers = read.csv(file = here("InputData/Downsizer_Stations.csv"))
#Account for timeframe of interest----
# StartDate = data.frame("April", "1", "2023", as.Date("2023-04-01"))
# EndDate = data.frame("May", "23", "2023", as.Date("2023-05-23"))
# colnames(StartDate) = c("month", "day", "year", "date")
# colnames(EndDate) = c("month", "day", "year", "date")
# ndays = seq(from = StartDate$date, to = EndDate$date, by = 'day') %>% length()
# ndays
# TimeFrame = seq(from = StartDate$date, to = EndDate$date, by = 'day')
#Extract the weather data from Downsizer_Original----
#Drop the first 42 rows of Downsizer
Downsizer = tail(Downsizer_Original, nrow(Downsizer_Original)-42) %>%data.frame()
colnames(Downsizer) = "Downsizer"
#Format the Downsizer dataframe to match the PRMS_Update DAT file----
##Calculate the number of columns after splitting the 1st column by the space delimiter----
ncols <- max(stringr::str_count(Downsizer$Downsizer))
ncols #creates 252 columns, but only the first 36 have content
colmn <- paste0("Col", 1:ncols) #creates a set of 252 columns named Col1, Col2, ....
colmn
##Split Downsizer into 253 columns by using spaces as delimiters----
Downsizer_Processed <-
tidyr::separate(
data = Downsizer,
col = Downsizer,
sep = " ",
into = colmn,
remove = FALSE
)
##Delete extra columns and apply column names----
Downsizer_Processed[38:253] = NULL
Downsizer_Processed[5:7] = NULL
Downsizer_Processed[1] = NULL
#Fill in the column names of Downsizer_Processed
colnames(Downsizer_Processed) = colnames(Headers)
colnames(Downsizer_Processed)
#Remove all NA columns from Downsizer_Processed
Downsizer_Processed <- select(Downsizer_Processed, -c(starts_with("NA")))
source(here("Scripts/DAT_Shell_Generation.R")) #Ignore the warning message:In eval(e, x, parent.frame()) :...
# change output file name for DAT File
source(here("Scripts/DAT_File_Manipulation.R"))
source(here("Scripts/PRISM_Scraper.R"))
View(Prism_Processed)
View(Downsizer_Processed)
git pull origin main
