# "AnnualReportedTotalDirect"
# "AnnualTotalStorage"
# "AnnualTotalDiversion"
# "Duplicate_Reports_Same_Owner"
# First, create "Owner"
# Joining 'ownerDF' to 'statDF' will create this column
# (Then "APPLICATION_PRIMARY_OWNER" can be renamed to "Owner")
statDF <- statDF %>% left_join(ownerDF, by = "APPLICATION_NUMBER", relationship = "many-to-one") %>%
rename(Owner = APPLICATION_PRIMARY_OWNER)
# NOTE
# It should be a "many-to-one" relationship,
# meaning that multiple rows of 'statDF' will match with one row of 'ownerDF'
# Verify that every column of 'statDF' has an owner specified (so no NA values)
stopifnot(!anyNA(statDF$Owner))
# The next three columns ("AnnualReportedTotalDirect", "AnnualTotalStorage",
# and "AnnualTotalDiversion") were calculated in 'dupMonths'
# Join these columns to 'statDF' using their shared columns
# In 'dupMonths', these column values should be the same for rows with the
# same "APPLICATION_NUMBER" and "YEAR" values
# But to simplify the process, join by more shared columns
# That way, each row of 'statDF' will have exactly one match in 'dupMonths'
# (By doing so, "one-to-one" can be specified in left_join() for an extra error check)
statDF <- left_join(statDF,
dupMonths %>%
select(APPLICATION_NUMBER, YEAR, MONTH, DIVERSION_TYPE,
AnnualReportedTotalDirect, AnnualTotalStorage, AnnualTotalDiversion),
by = c("APPLICATION_NUMBER", "YEAR", "MONTH", "DIVERSION_TYPE"), relationship = "one-to-one")
# Ensure that the new columns have been completely filled
stopifnot(!anyNA(statDF$AnnualReportedTotalDirect))
statDF %>% filter(is.na(AnnualReportedTotalDirect))
source("~/Github/DWRAT_DataScraping/Demand/Scripts/DuplicateMonths_Years.R")
# The main body of the script
# Read in the input CSV file ("Statistics_FINAL.csv")
statFinal <- read.csv("InputData/Statistics_FINAL.csv")
# Add the following columns to 'statFinal'
# Column G: TotalMonthlyDiverted
# Column H: AnnualReportedTotalDirect
# Column I: AnnualTotalStorage
# Column J: AnnualTotalDiversion
# Column K: NumberOfOccurencesWithinSingleReport
# Column L: OccurencesAcrossReports
# Start with the first column "TotalMonthlyDiverted"
# Create another variable that summarizes the total diversion and storage
# for each application number (separately for each month/year)
# (The only use types considered are "DIRECT" and "STORAGE")
tempDF <- statFinal %>%
filter(DIVERSION_TYPE %in% c("DIRECT", "STORAGE")) %>%
group_by(APPLICATION_NUMBER, YEAR, MONTH) %>%
summarize(TotalMonthlyDiverted = sum(AMOUNT, na.rm = TRUE), .groups = "drop")
# Join those results back to 'statFinal' using left_join()
# (The relationship is "many-to-one" because multiple rows in 'tempDF' will
#  use the same value from 'tempDF')
statFinal <- statFinal %>%
left_join(tempDF,
by = c("APPLICATION_NUMBER", "YEAR", "MONTH"),
relationship = "many-to-one")
# Perform similar steps for the next column, "AnnualReportedTotalDirect"
# Grouping will be done by "APPLICATION_NUMBER" and "YEAR"
# (And the "DIVERSION_TYPE" filter will be "DIRECT" only)
tempDF <- statFinal %>%
filter(DIVERSION_TYPE == "DIRECT") %>%
group_by(APPLICATION_NUMBER, YEAR) %>%
summarize(AnnualReportedTotalDirect = sum(AMOUNT, na.rm = TRUE), .groups = "drop")
# Join those results back to 'statFinal' using left_join()
# (The relationship is "many-to-one" because multiple rows in 'tempDF' will
#  use the same value from 'tempDF')
statFinal <- statFinal %>%
left_join(tempDF,
by = c("APPLICATION_NUMBER", "YEAR"),
relationship = "many-to-one")
# The next column is "AnnualTotalStorage"
# The steps are exactly the same as for "AnnualReportedTotalDirect" except
# "DIVERSION_TYPE" is "STORAGE" only
tempDF <- statFinal %>%
filter(DIVERSION_TYPE == "STORAGE") %>%
group_by(APPLICATION_NUMBER, YEAR) %>%
summarize(AnnualTotalStorage = sum(AMOUNT, na.rm = TRUE), .groups = "drop")
# Join those results back to 'statFinal' using left_join()
# (The relationship is "many-to-one" because multiple rows in 'tempDF' will
#  use the same value from 'tempDF')
statFinal <- statFinal %>%
left_join(tempDF,
by = c("APPLICATION_NUMBER", "YEAR"),
relationship = "many-to-one")
# After that, calculate "AnnualTotalDiversion"
# It is simply the sum of "AnnualReportedTotalDirect" and "AnnualTotalStorage"
statFinal <- statFinal %>%
mutate(AnnualTotalDiversion = AnnualReportedTotalDirect + AnnualTotalStorage)
# Finally, only two columns remain
# They will also require a temporary DF that is joined to 'statFina'
# Start with "NumberOfOccurencesWithinSingleReport"
# Filter 'statFinal to only "DIRECT" use records
# Count the number of reports with the same "APPLICATION_NUMBER", "YEAR", and
# "TotalMonthlyDiverted" values
# (There is one important exception, however; if "TotalMonthlyDiverted" is 0,
#  the value of this new column will also be 0)
tempDF <- statFinal %>%
filter(DIVERSION_TYPE == "DIRECT") %>%
group_by(APPLICATION_NUMBER, YEAR, TotalMonthlyDiverted) %>%
summarize(NumberOfOccurencesWithinSingleReport = n(), .groups = "drop") %>%
mutate(NumberOfOccurencesWithinSingleReport =
if_else(TotalMonthlyDiverted == 0, 0L, NumberOfOccurencesWithinSingleReport))
# Join this new column to 'statFinal'
statFinal <- statFinal %>%
left_join(tempDF,
by = c("APPLICATION_NUMBER", "YEAR", "TotalMonthlyDiverted"),
relationship = "many-to-one")
# The final column "OccurencesAcrossReports" is similar
# It counts one-twelfth the number of entries with "DIRECT" usage
# that have the same "APPLICATION_NUMBER" and "AnnualTotalDiversion" values
# (And similar to before, if "AnnualTotalDiversion" is 0, this column will be 0 too)
tempDF <- statFinal %>%
filter(DIVERSION_TYPE == "DIRECT") %>%
group_by(APPLICATION_NUMBER, AnnualTotalDiversion) %>%
summarize(OccurencesAcrossReports = n(), .groups = "drop") %>%
mutate(OccurencesAcrossReports =
if_else(AnnualTotalDiversion == 0, 0, OccurencesAcrossReports / 12))
# Join these results to 'statFinal'
statFinal <- statFinal %>%
left_join(tempDF,
by = c("APPLICATION_NUMBER", "AnnualTotalDiversion"),
relationship = "many-to-one")
# After that, save 'statFinal' to a new XLSX file
write.xlsx(statFinal, "OutputData/DuplicateMonths_Years_Scripted.xlsx", overwrite = TRUE)
statFinal %>% filter(is.na(AnnualReportedTotalDirect))
statFinal %>% filter(is.na(TotalMonthlyDiverted))
# Read in the input CSV file ("Statistics_FINAL.csv")
statFinal <- read.csv("InputData/Statistics_FINAL.csv")
# Create another variable that summarizes the total diversion and storage
# for each application number (separately for each month/year)
# (The only use types considered are "DIRECT" and "STORAGE")
tempDF <- statFinal %>%
filter(DIVERSION_TYPE %in% c("DIRECT", "STORAGE")) %>%
group_by(APPLICATION_NUMBER, YEAR, MONTH) %>%
summarize(TotalMonthlyDiverted = sum(AMOUNT, na.rm = TRUE), .groups = "drop")
tempDF %>% filter(is.na(TotalMonthlyDiverted))
# Join those results back to 'statFinal' using left_join()
# (The relationship is "many-to-one" because multiple rows in 'tempDF' will
#  use the same value from 'tempDF')
statFinal <- statFinal %>%
left_join(tempDF,
by = c("APPLICATION_NUMBER", "YEAR", "MONTH"),
relationship = "many-to-one")
statFinal %>% filter(is.na(TotalMonthlyDiverted))
tempDF %>% filter(APPLICATION_NUMBER == "A011859")
# Read in the input CSV file ("Statistics_FINAL.csv")
statFinal <- read.csv("InputData/Statistics_FINAL.csv")
# Create another variable that summarizes the total diversion and storage
# for each application number (separately for each month/year)
# (The only use types considered are "DIRECT" and "STORAGE")
tempDF <- statFinal %>%
filter(DIVERSION_TYPE %in% c("DIRECT", "STORAGE")) %>%
group_by(APPLICATION_NUMBER, YEAR, MONTH) %>%
summarize(TotalMonthlyDiverted = sum(AMOUNT, na.rm = TRUE), .groups = "drop")
# Join those results back to 'statFinal' using left_join()
# (The relationship is "many-to-one" because multiple rows in 'tempDF' will
#  use the same value from 'tempDF')
statFinal <- statFinal %>%
left_join(tempDF,
by = c("APPLICATION_NUMBER", "YEAR", "MONTH"),
relationship = "many-to-one") %>%
mutate(TotalMonthlyDiverted = replace_na(TotalMonthlyDiverted, 0))
statFinal %>% filter(is.na(TotalMonthlyDiverted))
source("~/Github/DWRAT_DataScraping/Demand/Scripts/DuplicateMonths_Years.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/DuplicateReport_SameOwner.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Expected_Demand.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Beneficial_Use_Return_Flow.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Beneficial_Use_Return_Flow.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Beneficial_Use_Return_Flow.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Beneficial_Use_Return_Flow.R")
?any_of
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Beneficial_Use_Return_Flow.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Beneficial_Use_Return_Flow.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Beneficial_Use_Return_Flow.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Beneficial_Use_Return_Flow.R")
?across
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Beneficial_Use_Return_Flow.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Diversion_Out_Of_Season.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Missing_RMS_Reports.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/QAQC_Working_File.R")
source("~/Github/DWRAT_DataScraping/Demand/ModuleAndScriptComparisons/Compare Modules and Scripts.R")
list.dirs("Module and Script Comparisons/", recursive = FALSE, full.names = FALSE)
list.dirs("ModuleAndScriptComparisons/", recursive = FALSE, full.names = FALSE)
list.dirs("ModuleAndScriptComparisons/", recursive = FALSE, full.names = FALSE)
getUserChoice()
source("~/Github/DWRAT_DataScraping/Demand/ModuleAndScriptComparisons/Compare Modules and Scripts.R")
paste0("ModuleAndScriptComparisons/", comparisonList[i])
source("~/Github/DWRAT_DataScraping/Demand/ModuleAndScriptComparisons/Compare Modules and Scripts.R")
# Ask the user to specify which comparisons to run
comparisonList <- getUserChoice()
i = 1
# Notify the user which module is being checked
cat(paste0("Initiating a comparison for the '", comparisonList[i], "' module..."))
# Check the directory to verify that the required files are present
dirCheck(comparisonList[i])
paste0("ModuleAndScriptComparisons/", comparisonList[i])
list.files(paste0("ModuleAndScriptComparisons/", comparisonList[i]))
list.files(paste0("ModuleAndScriptComparisons/", comparisonList[i]), full.names = TRUE)
list.files(paste0("ModuleAndScriptComparisons/", comparisonList[i]), full.names = TRUE) %>%
str_subset("\\.xlsx$") %>% str_subset("Scripted", negate = TRUE)
################# Use the URL's to pull the flat files to the correct location. Do not run these lines again so there is a static data source. ###########################################
####Download POD flat file from the URL(Public)
##ewrims_flat_file <- read.csv(url("https://data.ca.gov/dataset/65296e4a-2417-466b-af8c-577f1936ba75/resource/e8235902-adc3-48ce-ab96-fcf230a09208/download/ewrims_flat_file.csv"))
##Download POD flat file from the URL(Internal DWR)
ewrims_flat_file <- read.csv(url("http://intapps.waterboards.ca.gov/downloadFile/faces/flatFilesEwrims.xhtml?fileName=ewrims_flat_file.csv"))
install.packages("geosphere")
system("ipconfig", intern= TRUE)
?system
system("ipconfig", intern = TRUE)
install.packages(c("geosphere", "pracma"))
system("ipconfig", intern = TRUE)
system("ipconfig", intern = TRUE)
?system
?system2
system("ipconfig", intern = TRUE) %>%
system2("ipconfig")
system2("ipconfig")
test <- system2("ipconfig")
test <- system2("ipconfig", stdout = TRUE)
test
test <- system("ipconfig", intern = TRUE)
test <- system("ipconfig", intern = TRUE)
test2 <- system2("ipconfig", stdout = TRUE)
sum(test = test2)
sum(test == test2)
?write.csv
#Load Packages- This step must be done each time the project is opened. ----
library(tidyverse)
?write_csv
url("http://intapps.waterboards.ca.gov/downloadFile/faces/flatFilesEwrims.xhtml?fileName=ewrims_flat_file_pod.csv")
?download.file
# Save the POD flat file
download.file("http://intapps.waterboards.ca.gov/downloadFile/faces/flatFilesEwrims.xhtml?fileName=ewrims_flat_file_pod.csv",
"RawData/ewrims_flat_file_pod.csv", mode = "wb")
# Save the POD flat file
download.file("http://intapps.waterboards.ca.gov/downloadFile/faces/flatFilesEwrims.xhtml?fileName=ewrims_flat_file_pod.csv",
"RawData/ewrims_flat_file_pod.csv", mode = "wb", quiet = TRUE)
# Get the master flat file as well
download.file("http://intapps.waterboards.ca.gov/downloadFile/faces/flatFilesEwrims.xhtml?fileName=ewrims_flat_file.csv",
"RawData/ewrims_flat_file.csv", mode = "wb", quiet = TRUE)
# Download the Water Rights Annual Water Use Report file next
download.file("http://intapps.waterboards.ca.gov/downloadFile/faces/flatFilesEwrims.xhtml?fileName=water_use_report.csv",
"RawData/water_use_report.csv", mode = "wb", quiet = TRUE)
# Download the Water Rights Annual Water Use Report file next
download.file("http://intapps.waterboards.ca.gov/downloadFile/faces/flatFilesEwrims.xhtml?fileName=water_use_report.csv",
"RawData/water_use_report.csv", mode = "wb", quiet = TRUE)
# Download the Water Rights Annual Water Use Report file next
read_csv("http://intapps.waterboards.ca.gov/downloadFile/faces/flatFilesEwrims.xhtml?fileName=water_use_report.csv") %>%
write_csv("RawData/water_use_report.csv")
# Download the Water Rights Annual Water Use Report file next
# read_csv() and write_csv() are used instead of download.file() because the download time for this file is too long
read_csv("http://intapps.waterboards.ca.gov/downloadFile/faces/flatFilesEwrims.xhtml?fileName=water_use_report.csv", show_col_types = FALSE) %>%
write_csv("RawData/water_use_report.csv")
# Save the POD flat file
download.file("http://intapps.waterboards.ca.gov/downloadFile/faces/flatFilesEwrims.xhtml?fileName=ewrims_flat_file_pod.csv",
"RawData/ewrims_flat_file_pod.csv", mode = "wb", quiet = TRUE)
# Get the master flat file as well
download.file("http://intapps.waterboards.ca.gov/downloadFile/faces/flatFilesEwrims.xhtml?fileName=ewrims_flat_file.csv",
"RawData/ewrims_flat_file.csv", mode = "wb", quiet = TRUE)
# Download the Water Rights Annual Water Use Report file next
# read_csv() and write_csv() are used instead of download.file() because the download time for this file is too long
read_csv("http://intapps.waterboards.ca.gov/downloadFile/faces/flatFilesEwrims.xhtml?fileName=water_use_report.csv", show_col_types = FALSE) %>%
write_csv("RawData/water_use_report.csv")
# Save the Water Rights Uses and Seasons flat file as well
download.file("http://intapps.waterboards.ca.gov/downloadFile/faces/flatFilesEwrims.xhtml?fileName=ewrims_flat_file_use_season.csv",
"RawData/ewrims_flat_file_use_season.csv", mode = "wb", quiet = TRUE)
# Get the Water Rights Parties flat file after that
download.file("http://intapps.waterboards.ca.gov/downloadFile/faces/flatFilesEwrims.xhtml?fileName=ewrims_flat_file_party.csv",
"RawData/ewrims_flat_file_party.csv", mode = "wb", quiet = TRUE)
# Get the Water Rights Parties flat file after that
# (It is also a big file that requires read_csv() instead of download.file())
read_csv("http://intapps.waterboards.ca.gov/downloadFile/faces/flatFilesEwrims.xhtml?fileName=ewrims_flat_file_party.csv", show_col_types = FALSE) %>%
write_csv("RawData/ewrims_flat_file_party.csv")
problems()
?read_csv
# Get the Water Rights Parties flat file after that
# (It is also a big file that would work better with read_csv() instead of download.file())
read_csv("http://intapps.waterboards.ca.gov/downloadFile/faces/flatFilesEwrims.xhtml?fileName=ewrims_flat_file_party.csv", show_col_types = FALSE, col_types = cols(.default = col_character())) %>%
write_csv("RawData/ewrims_flat_file_party.csv")
?pracma
# install.packages("readxl")
# install.packages("geosphere")
# install.packages("stringi")
# install.packages("stringr")
# install.packages("pracma")
#Load Packages- This step must be done each time the project is opened. ----
library(tidyverse)
library(readxl)
library(geosphere)
library(stringi)
library(stringr)
library(pracma) #required for strcmpi function
source("~/Github/DWRAT_DataScraping/Demand/Scripts/QAQC_Combine_Flat_Files.R")
names(ewrims_flat_file_use_season_Combined_USE_STATUS)
names(ewrims_flat_file_use_season_Combined_USE_STATUS) %>% str_subset("COLLEC")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
# Read the POD flat file next
ewrims_flat_file_use_season <- read.csv("RawData/ewrims_flat_file_pod.csv")
names(ewrims_flat_file_use_season)
names(ewrims_flat_file_use_season) %>% str_subset("STAT")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/QAQC_Combine_Flat_Files.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/QAQC_Combine_Flat_Files.R")
?read.csv
# Remove unnecessary variables again to save memory
remove(ewrims_flat_file, ewrims_flat_file_use_season, ewrims_flat_file_use_season_Combined,
ewrims_flat_file_use_season_Combined_COLLECTION_SEASON_STATUS,
ewrims_flat_file_use_season_Combined_DIRECT_DIV_SEASON_STATUS,
ewrims_flat_file_use_season_Combined_USE_STATUS)
# Read back in the filtered ewrims flat file
Duplicate_Reports_POD <- read.csv("RawData/ewrims_flat_file_WITH_FILTERS.csv")
# Read back in the filtered ewrims flat file
Duplicate_Reports_POD <- read.csv("InputData/ewrims_flat_file_WITH_FILTERS.csv")
# Select a
Duplicate_Reports_POD <- Duplicate_Reports_POD %>%
select("WR_WATER_RIGHT_ID", "APPLICATION_NUMBER","POD_ID","LATITUDE","LONGITUDE","SOURCE_NAME","APPLICATION_PRIMARY_OWNER" ,"PRIMARY_OWNER_NAME","CERTIFICATE_ID","PERMIT_ID",
"LICENSE_ID",	"WATER_RIGHT_TYPE",	"WATER_RIGHT_STATUS",	"PRIMARY_OWNER_ENTITY_TYPE","MAX_DD_APPL","MAX_DD_UNITS","MAX_DD_ANN","MAX_STORAGE","MAX_TAKEN_FROM_SOURCE","USE_DIRECT_DIV_ANNUAL_AMOUNT",
"USE_STORAGE_AMOUNT",	"POD_NUMBER",	"POD_STATUS",	"DIRECT_DIVERSION_RATE",	"POD_TYPE")
# install.packages("pracma")
#Load Packages- This step must be done each time the project is opened. ----
library(tidyverse)
library(readxl)
library(geosphere)
library(stringi)
library(stringr)
library(pracma) #required for strcmpi function
i = 3
i = 3
for (i in 1:5) {
print("Hi")
}
i = 3
for (i in 1:5) {
print("Hi")
}
# Read 'Duplicate_Reports_POD_FINAL_List' back in as another variable
flatf <- read.csv("InputData/Duplicate_Reports_POD_FINAL_List.csv")
######################################################################## List of Application from GIS Step ####################################################################################
# Import GIS data reviewed by SDU on 7/17/2023
Application_Number <- read_xlsx("InputData/RR_pod_points_MAX_MAF__20230717.xlsx")
# Change the column name from "APPL_ID" to "APPLICATION_NUMBER"
# Keep only the "APPLICATION_NUMBER" and "FREQUENCY" columns
Application_Number <- Application_Number %>%
rename(APPLICATION_NUMBER = APPL_ID) %>%
select(APPLICATION_NUMBER, FREQUENCY)
# Read in the eWRIMS Flat File
ewrims_flat_file <- read.csv("RawData/ewrims_flat_file.csv")
# Perform an inner join using "APPLICATION_NUMBER"
# Multiple rows in 'Application_Number' may match with multiple rows in 'ewrims_flat_file'
ewrims_flat_file_Combined <- inner_join(Application_Number, ewrims_flat_file, by = "APPLICATION_NUMBER",
relationship = "many-to-many")
# Output 'ewrims_flat_file_Combined' to a folder
write.csv(ewrims_flat_file_Combined,"InputData/ewrims_flat_file_WITH_FILTERS.csv", row.names = FALSE)
######################################################################## Break ####################################################################################
# Each of the spreadsheets that use the water use report need different filters so only the date is filtered here
# Read in the (very large) water use report flat file
water_use_report <- read.csv("RawData/water_use_report.csv")
# Rename "APPL_ID" to "APPLICATION_NUMBER" to allow joins with 'Application_Number'
water_use_report <- water_use_report %>%
rename(APPLICATION_NUMBER = APPL_ID)
# Perform an inner join (it is a many-to-many relationship once again)
water_use_report_Combined <- inner_join(Application_Number, water_use_report, by = "APPLICATION_NUMBER",
relationship = "many-to-many")
# Remove all data from before 2014 because this is when the data structure changes in the system
water_use_report_Date <- water_use_report_Combined %>%
filter(YEAR >= 2014)
# Output the data to a CSV file
write.csv(water_use_report_Date,"InputData/water_use_report_DATE.csv", row.names = FALSE)
# Remove variables from the environment that will no longer be used (free up memory)
remove(ewrims_flat_file_Combined, water_use_report, water_use_report_Combined, water_use_report_Date)
######################################################################## Break ####################################################################################
# Read the POD flat file next
ewrims_flat_file_use_season <- read.csv("RawData/ewrims_flat_file_pod.csv")
# Perform another inner join
ewrims_flat_file_use_season_Combined <- inner_join(Application_Number, ewrims_flat_file_use_season, by = "APPLICATION_NUMBER",
relationship = "many-to-many")
# Remove rows where "APPLICATION_NUMBER" starts with "S" (statements of diversion and use)
ewrims_flat_file_use_season_Combined <- ewrims_flat_file_use_season_Combined %>%
filter(!grepl("^S", APPLICATION_NUMBER))
# Filter by use status next
ewrims_flat_file_use_season_Combined_USE_STATUS <- ewrims_flat_file_use_season_Combined %>%
filter(USE_STATUS %in% c("Added by change order", "Added by correction order",
"Added under section 798 of Regs", "Migrated from old WRIMS data",
"Requested when filed", ""))
# Perform additional filters for collection season status
ewrims_flat_file_use_season_Combined_COLLECTION_SEASON_STATUS <- ewrims_flat_file_use_season_Combined_USE_STATUS %>%
filter(COLLECTION_SEASON_STATUS %in% c("Migrated from old WRIMS data", "Reduced by order",
"Reduced when licensed", "Requested when filed", ""))
################################################################# DIRECT_DIV_SEASON_STATUS ########################################################################
# Filter 'ewrims_flat_file_use_season_Combined_COLLECTION_SEASON_STATUS' further
# This time, check the three different status columns
ewrims_flat_file_use_season_Combined_DIRECT_DIV_SEASON_STATUS <- ewrims_flat_file_use_season_Combined_COLLECTION_SEASON_STATUS %>%
filter(DIRECT_DIV_SEASON_STATUS %in% c("Migrated from old WRIMS data", "Reduced by order",
"Reduced when licensed", "Requested when filed", ""))
# Write the output to a file
write.csv(ewrims_flat_file_use_season_Combined_DIRECT_DIV_SEASON_STATUS,
"InputData/ewrims_flat_file_use_season_WITH_FILTERS.csv", row.names = FALSE)
# Remove unnecessary variables again to save memory
remove(ewrims_flat_file, ewrims_flat_file_use_season, ewrims_flat_file_use_season_Combined,
ewrims_flat_file_use_season_Combined_COLLECTION_SEASON_STATUS,
ewrims_flat_file_use_season_Combined_DIRECT_DIV_SEASON_STATUS,
ewrims_flat_file_use_season_Combined_USE_STATUS)
###########################################################################Duplicate_Reports_POD(F1)###################################################################
#################################################################################### Break ############################################################################
# Read back in the filtered ewrims flat file
Duplicate_Reports_POD <- read.csv("InputData/ewrims_flat_file_WITH_FILTERS.csv")
# Select a subset of these columns
Duplicate_Reports_POD_FINAL_List <- Duplicate_Reports_POD %>%
select("WR_WATER_RIGHT_ID", "APPLICATION_NUMBER","POD_ID","LATITUDE","LONGITUDE","SOURCE_NAME","APPLICATION_PRIMARY_OWNER" ,"PRIMARY_OWNER_NAME","CERTIFICATE_ID","PERMIT_ID",
"LICENSE_ID",	"WATER_RIGHT_TYPE",	"WATER_RIGHT_STATUS",	"PRIMARY_OWNER_ENTITY_TYPE","MAX_DD_APPL","MAX_DD_UNITS","MAX_DD_ANN","MAX_STORAGE","MAX_TAKEN_FROM_SOURCE","USE_DIRECT_DIV_ANNUAL_AMOUNT",
"USE_STORAGE_AMOUNT",	"POD_NUMBER",	"POD_STATUS",	"DIRECT_DIVERSION_RATE",	"POD_TYPE")
# Write the shortened variable to a new CSV file
write.csv(Duplicate_Reports_POD_FINAL_List,"InputData/Duplicate_Reports_POD_FINAL_List.csv", row.names = FALSE)
# First, read in a flat file
Priority_Date <- read.csv("InputData/ewrims_flat_file_WITH_FILTERS.csv")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/GIS_POD_Flat_File_Prep.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/GIS_POD_Flat_File_Prep.R")
library(tidyverse)
library(readxl)
library(geosphere)
library(stringi)
library(stringr)
library(pracma) #required for strcmpi function
source("~/Github/DWRAT_DataScraping/Demand/Scripts/GIS_POD_Flat_File_Prep.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/GIS_POD_Flat_File_Prep.R")
?knitr::render()
?rmarkdown::render
install.packages("tinytex")
library(tinytex)
tinytex::install_tinytex()
options(timeout = 10000)
tinytex::install_tinytex()
tinytex::install_tinytex()
?install.packages
install.packages("rmarkdown")
library(rmarkdown)
install.packages("rmarkdown")
rmarkdown::github_document()
source("~/Github/DWRAT_DataScraping/Demand/Scripts/GIS_POD_Flat_File_Prep.R")
problems()
warnings()
source("~/Github/DWRAT_DataScraping/Demand/Scripts/GIS_POD_Flat_File_Prep.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Priority_Date_Preprocessing.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Priority_Date_Preprocessing.R")
################################################################### Diversion out of Season Part A ############################################################
#### Read in CSV
Diversion_out_of_Season_Part_A <- read.csv("Flat_Files/ewrims_flat_file_use_season_WITH_FILTERS.csv")
test <- read.csv("RawData/ewrims_flat_file_use_season_WITH_FILTERS.csv")
test <- read.csv("InputData/ewrims_flat_file_use_season_WITH_FILTERS.csv")
# Read in the use season flat file
Diversion_out_of_Season_Part_A <- read.csv("RawData/ewrims_flat_file_use_season.csv")
# Extract a portion of the table
Diversion_out_of_Season_Part_A_FINAL <- Diversion_out_of_Season_Part_A %>%
select(APPLICATION_NUMBER, USE_STATUS, DIRECT_SEASON_START_MONTH_1, DIRECT_SEASON_START_MONTH_2,
DIRECT_DIV_SEASON_END_MONTH_1, DIRECT_DIV_SEASON_END_MONTH_2, STORAGE_SEASON_START_MONTH_1,
STORAGE_SEASON_START_MONTH_2, STORAGE_SEASON_END_MONTH_1, STORAGE_SEASON_END_MONTH_2)
Diversion_out_of_Season_Part_A_FINAL %>% unique() %>% nrow()
# Extract a portion of the table
Diversion_out_of_Season_Part_A_FINAL <- Diversion_out_of_Season_Part_A %>%
select(APPLICATION_NUMBER, USE_STATUS, DIRECT_SEASON_START_MONTH_1, DIRECT_SEASON_START_MONTH_2,
DIRECT_DIV_SEASON_END_MONTH_1, DIRECT_DIV_SEASON_END_MONTH_2, STORAGE_SEASON_START_MONTH_1,
STORAGE_SEASON_START_MONTH_2, STORAGE_SEASON_END_MONTH_1, STORAGE_SEASON_END_MONTH_2) %>%
unique()
Diversion_out_of_Season_Part_A_FINAL$APPLICATION_NUMBER[!(Diversion_out_of_Season_Part_A_FINAL$APPLICATION_NUMBER %in% test$APPLICATION_NUMBER)]
# Read the POD flat file next
ewrims_flat_file_use_season <- read.csv("RawData/ewrims_flat_file_use_season.csv")
names(ewrims_flat_file_use_season)
names(ewrims_flat_file_use_season) %>% str_subset("STATUS")
# Read the use season flat file next
ewrims_flat_file_use_season <- read.csv("RawData/ewrims_flat_file_use_season.csv")
# Perform another inner join
ewrims_flat_file_use_season_Combined <- inner_join(Application_Number, ewrims_flat_file_use_season, by = "APPLICATION_NUMBER",
relationship = "many-to-many")
# Remove rows where "APPLICATION_NUMBER" starts with "S" (statements of diversion and use)
ewrims_flat_file_use_season_Combined <- ewrims_flat_file_use_season_Combined %>%
filter(!grepl("^S", APPLICATION_NUMBER))
# Filter by use status next
ewrims_flat_file_use_season_Combined_USE_STATUS <- ewrims_flat_file_use_season_Combined %>%
filter(USE_STATUS %in% c("Added by change order", "Added by correction order",
"Added under section 798 of Regs", "Migrated from old WRIMS data",
"Requested when filed", ""))
# Perform additional filters for collection season status
ewrims_flat_file_use_season_Combined_COLLECTION_SEASON_STATUS <- ewrims_flat_file_use_season_Combined_USE_STATUS %>%
filter(COLLECTION_SEASON_STATUS %in% c("Migrated from old WRIMS data", "Reduced by order",
"Reduced when licensed", "Requested when filed", ""))
# Perform additional filters for collection season status
ewrims_flat_file_use_season_Combined_COLLECTION_SEASON_STATUS <- ewrims_flat_file_use_season_Combined_USE_STATUS %>%
filter(COLLECTION_SEASON_STATUS_1 %in% c("Migrated from old WRIMS data", "Reduced by order",
"Reduced when licensed", "Requested when filed", "") |
COLLECTION_SEASON_STATUS_2 %in% c("Migrated from old WRIMS data", "Reduced by order",
"Reduced when licensed", "Requested when filed", "") |
COLLECTION_SEASON_STATUS_3 %in% c("Migrated from old WRIMS data", "Reduced by order",
"Reduced when licensed", "Requested when filed", ""))
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Priority_Date_Preprocessing.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Priority_Date_Preprocessing.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Priority_Date_Preprocessing.R")
# Priority Date Module
source("Scripts/Priority_Date.R")
source("~/Github/DWRAT_DataScraping/Demand/Scripts/Priority_Date.R")
# Read in from Priority date calculator
Priority_Date <- read_xlsx("IntermediateData/Priority_Date_Scripted.xlsx")
warnings()
# Read in from Priority date calculator
Priority_Date <- read_xlsx("IntermediateData/Priority_Date_Scripted.xlsx", col_types = "text")
# Read in from Priority date calculator
Priority_Date <- read_xlsx("IntermediateData/Priority_Date_Scripted.xlsx", col_types = "text")
read_xlsx("IntermediateData/Priority_Date_Scripted.xlsx", col_types = "text") %>%
select(APPLICATION_NUMBER, ASSIGNED_PRIORITY_DATE, PRE_1914, RIPARIAN, APPROPRIATIVE, APPROPRIATIVE_DATE_SOURCE, STATEMENT_PRIORITY_SOURCE)
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
