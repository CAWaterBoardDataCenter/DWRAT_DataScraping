library(readr)
##Set Default download folder ----
eCaps <- list(
chromeOptions =
list(prefs = list(
"profile.default_content_settings.popups" = 0L,
"download.prompt_for_download" = FALSE,
"download.default_directory" = gsub(pattern = '/', replacement = '\\\\', x = here("WebData")) # download.dir
)
)
)
default_folder = here("WebData")
## Open a chrome browser session with RSelenium ----
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='108.0.5359.71',
port = free_port(),
)
remDr <- rs_driver_object$client
#Input Data----
#Import RAWS stations
Stations = read.csv("InputData/Raws_Stations.csv")
#Define Dates
StartDates = data.frame("December", "01", "2022")
EndDates = data.frame("December", "28", "2022")
colnames(StartDates) = c("month", "day", "year")
colnames(EndDates) = c("month", "day", "year")
ndays = 28 #change depending on your start and end dates
#Scrape RAWS Data----
#Create list to hold RAWS dataframes
DF_List <- list()
#Navigate to RAWS website
for (i in 1:nrow(Stations)){
#i = 1
remDr$navigate(paste0("https://wrcc.dri.edu/cgi-bin/rawMAIN.pl?ca", Stations$Station[i]))
#Switch to Left Frame named "List"
ListFrame <- remDr$findElement(using = "name", value = "List")
remDr$switchToFrame(ListFrame)
#Select Daily Summary Time Series Link
Link1 <- remDr$findElement(using = "link text", value = "Daily Summary Time Series")
Link1$clickElement()
#Switch to Right Frame named "Graph"
remDr$switchToFrame(NA)
GraphFrame <- remDr$findElement(using = "name", value = "Graph")
remDr$switchToFrame(GraphFrame)
# #Set the Starting Date
StartMonth <- remDr$findElement(using = "name", value = "smon")
StartMonth$sendKeysToElement(list(StartDates$month))
#
StartDay <- remDr$findElement(using = "name", value = "sday")
StartDay$sendKeysToElement(list(StartDates$day))
#
StartYear <- remDr$findElement(using = "name", value = "syea")
StartYear$sendKeysToElement(list(StartDates$year))
#Set the Ending Date
EndMonth <- remDr$findElement(using = "name", value = "emon")
EndMonth$sendKeysToElement(list(EndDates$month))
#
EndDay <- remDr$findElement(using = "name", value = "eday")
EndDay$sendKeysToElement(list(EndDates$day))
#
EndYear <- remDr$findElement(using = "name", value = "eyea")
EndYear$sendKeysToElement(list(EndDates$year))
#Uncheck "Elements marked with *" box
Elements <-remDr$findElement(using = "name", value = "qBasic")
Elements$clickElement()
#Select Air Temperature and Precipitation
Temp <- remDr$findElement(using = "name", value = "qAT")
Temp$clickElement()
Precip <- remDr$findElement(using = "name", value = "qPR")
Precip$clickElement()
#Select Metric Output units
Units <- remDr$findElement(using = "xpath", "//input[@value = 'M']")
Units$clickElement()
#Select HTML Output
Format <-remDr$findElement(using = "xpath", "//input[@value = 'H']")
Format$clickElement()
#Select the Data Summarization requirements
Summarization <-remDr$findElement(using = "xpath", "//input[@value = 'C']")
Summarization$clickElement()
#Apply physical limits QC to data
Limits <-remDr$findElement(using = "xpath", "//input[@value = 'Y' and @name = 'qc']")
Limits$clickElement()
#Represent Missing data as -999
Missing<-remDr$findElement(using = "name", value = "miss")
Missing$sendKeysToElement(list("-999"))
#Don't include valid observations for each element
Validity <-remDr$findElement(using = "xpath", "//input[@value = 'N' and @name = 'obs']")
Validity$clickElement()
#Click on Submit info button
Submit <-remDr$findElement(using = "xpath", "//input[@value = 'Submit Info']")
Submit$clickElement()
#Switch to Graph frame (the right hand frame)
remDr$switchToFrame(NA)
GraphFrame <- remDr$findElement(using = "name", value = "Graph")
remDr$switchToFrame(GraphFrame)
#Scrape from Graph Frame using RSelenium----
WeatherData <- remDr$findElement(using = "xpath", "//table/tbody")
WeatherDataText <- WeatherData$getElementText() %>% unlist() %>% data.frame()
#Manipulate WeatherDataText
nchar(WeatherDataText)
Headers <-substring(WeatherDataText,1,161)
Headers
WeatherDataBody <-substring(WeatherDataText, 162,nchar(WeatherDataText))
WeatherDataBody <- gsub("\\\n", " ", WeatherDataBody)
WeatherDataBody <- strsplit( WeatherDataBody, " ") %>% unlist %>% data.frame()
#Force WeatherDataBody into dataframe with 8 columns
WeatherDataBody <- split(WeatherDataBody,rep(1:ndays,each=8)) %>% data.frame %>% t() %>% data.frame()
DF_List[[i]] <- WeatherDataBody
}
RAWS_Names <- c("Date", "Year", "Day_Of_Year", "Day_Of_Run", "Tavg", "Tmax", "Tmin", "Precipitation")
for (DF in seq_along(DF_List)){
colnames(DF_List[[DF]]) <- RAWS_names
}
RAWS_Names <- c("Date", "Year", "Day_Of_Year", "Day_Of_Run", "Tavg", "Tmax", "Tmin", "Precipitation")
#Apply column names to all dataframes
for (DF in seq_along(DF_List)){
colnames(DF_List[[DF]]) <- RAWS_names
}
RAWS_Names <- c("Date", "Year", "Day_Of_Year", "Day_Of_Run", "Tavg", "Tmax", "Tmin", "Precipitation")
#Apply column names to all dataframes
for (DF in seq_along(DF_List)){
colnames(DF_List[[DF]]) <- RAWS_Names
}
invisible(lapply(names(DF_List),function(x)
assign(x,DF_List[[x]],.GlobalEnv)))
ls()
invisible(lapply(names(DF_List),function(x)
assign(x,DF_List[[x]],.GlobalEnv)))
ls()
invisible(lapply(names(DF_List),function(x)
assign(x,DF_List[[x]],.GlobalEnv)))
lapply(names(DF_List),function(x)
assign(x,DF_List[[x]],.GlobalEnv))
ls()
lapply(names(DF_List),function(x)
assign(x,DF_List[[x]],.GlobalEnv))
for (i in seq(DF_List))
assign(paste0("df", i), df.list[[i]])
for (i in seq(DF_List))
assign(paste0("df", i), DF_List[[i]])
names(DF_List) <- lapply(seq_along(DF_List),
function(i) names(DF_List)[[i]] = paste0("RAWS_", Stations$Station[i]))
for (i in seq(DF_List))
assign(i, DF_List[[i]])
for (i in seq(DF_List))
assign(i, DF_List[[i]])
lapply(names(DF_List),function(x)
assign(x,DF_List[[x]],.GlobalEnv))
ls()
RAWS_CBOO <- select(RAWS_CBOO, -c(Tavg: Tmin))
RAWS_CSRS$Precipitation <- NULL
write.csv(RAWS_CBOO, here("WebData\RAWS_CBOO.csv"))
write.csv(RAWS_CBOO, here("WebData/RAWS_CBOO.csv"), row.names = FALSE)
write.csv(RAWS_CBOO, here("WebData/RAWS_CBOO.csv"), row.names = FALSE)
write.csv(RAWS_CHAW, here("WebData/RAWS_CHAW.csv"), row.names = FALSE)
write.csv(RAWS_CSRS, here("WebData/RAWS_CSRS.csv"), row.names = FALSE)
write.csv(RAWS_CLYO, here("WebData/RAWS_CLYO.csv"), row.names = FALSE)
# Set up RSelenium----
## load packages ----
library(RSelenium)
library(tidyverse)
library(netstat)
library(here)
library(dplyr)
library(readr)
# Import CNRFC Temperature stations----
CNRFC_Stations <- read.csv("InputData/CNRFC_Stations.csv")
View(CNRFC_Stations)
TestVector = c("Payman", "Alemi", "Water Rights")
data.frame(TestVector)
TestVector = data.frame(TestVector)
View(TestVector)
##Set Default download folder ----
eCaps <- list(
chromeOptions =
list(prefs = list(
"profile.default_content_settings.popups" = 0L,
"download.prompt_for_download" = FALSE,
"download.default_directory" = gsub(pattern = '/', replacement = '\\\\', x = here("WebData")) # download.dir
)
)
)
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='108.0.5359.71',
port = free_port(),
extraCapabilities = eCaps
)
remDr <- rs_driver_object$client
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='107.0.5359.71',
port = free_port(),
extraCapabilities = eCaps
)
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='108.0.5359.125',
port = free_port(),
extraCapabilities = eCaps
)
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='108.0.5359.125',
port = free_port(),
extraCapabilities = eCaps
)
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='108.0.5359.',
port = free_port(),
extraCapabilities = eCaps
)
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='108.0.5359.',
port = free_port(),
extraCapabilities = eCaps
)
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='108.0.5359.71',
port = free_port(),
extraCapabilities = eCaps
)
remDr <- rs_driver_object$client
Stations$Station[1]
CNRFC_stations$stations
CNRFC_Stations$Stations
CNRFC_Stations$Stations[1]
CNRFC_Stations$Stations[5]
i = 1
CNRFC_Stations$Stations[i]
nrow(CNRFC_Stations)
#Navigate to CNRFC website----
for (i in 1:nrow(CNRFC_Stations)){
CNRFC <- paste0("https://www.cnrfc.noaa.gov/temperaturePlots_hc.php?id=", CNRFC_Stations$Stations[i])
remDr$navigate(CNRFC)
#Select Chart Menu
ChartMenu <- remDr$findElement(using = "xpath", "//button[@aria-label = 'View chart menu']")
ChartMenu$clickElement()
#Download as CSV
CSVDownload <- remDr$findElement(using = "xpath", "//ul//li[contains(., 'CSV')]")
CSVDownload$clickElement()
}
# Set up RSelenium -------------------------------------------------------
## load packages ----
library(RSelenium)
library(tidyverse)
library(netstat)
library(here)
library(dplyr)
library(readr)
# Import CNRFC Temperature stations----
CNRFC_Stations <- read.csv("InputData/CNRFC_Stations.csv")
##Set Default download folder ----
eCaps <- list(
chromeOptions =
list(prefs = list(
"profile.default_content_settings.popups" = 0L,
"download.prompt_for_download" = FALSE,
"download.default_directory" = gsub(pattern = '/', replacement = '\\\\', x = here("WebData")) # download.dir
)
)
)
default_folder <- eCaps$chromeOptions$prefs$download.default_directory
#
## Open a chrome browser session with RSelenium ----
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='108.0.5359.71',
port = free_port(),
extraCapabilities = eCaps
)
remDr <- rs_driver_object$client
#Navigate to CNRFC website
for (i in 1:nrow(CNRFC_Stations)){
CNRFC <- paste0("https://www.cnrfc.noaa.gov/temperaturePlots_hc.php?id=", CNRFC_Stations$Stations[i])
remDr$navigate(CNRFC)
#Select Chart Menu
ChartMenu <- remDr$findElement(using = "xpath", "//button[@aria-label = 'View chart menu']")
ChartMenu$clickElement()
#Download as CSV
CSVDownload <- remDr$findElement(using = "xpath", "//ul//li[contains(., 'CSV')]")
CSVDownload$clickElement()
}
#Install and load libraries
library(dplyr)
library(tidyverse)
library(here)
library(lubridate) #for make_date function
#Import DAT stuff
DAT_File <- read.delim(here("InputData/data_update_to_11.30.2022.txt"), sep = "\t")
DAT_Fields <- read.csv(here("InputData/DAT_Fields.csv"))
#Set DAT_File column names
colnames(DAT_File) <- colnames(DAT_Fields)
#Notes about DAT_File fields----
#22 Runoff fields, always equal 1
#6 date-time fields, pre-filled from 1/1/1990 through 9/30/2023
#15 precipitation fields
#8 temperature fields
#We will replace a subset of the data corresponding to our timeframe of interest
#Whittle the DAT_File to a subset corresponding to our timeframe of interest, "DAT_Shell"----
#Add a Timestep column
DAT_File$TimeStep <- make_date(year = DAT_File$Year,
month = DAT_File$month,
day = DAT_File$day)
#Install and load libraries
library(dplyr)
library(tidyverse)
library(here)
library(lubridate) #for make_date function
#Import DAT stuff
DAT_File <- read.delim(here("InputData/data_update_to_11.30.2022.txt"), sep = "\t")
DAT_Fields <- read.csv(here("InputData/DAT_Fields.csv"))
#Set DAT_File column names
colnames(DAT_File) <- colnames(DAT_Fields)
#Notes about DAT_File fields----
#22 Runoff fields, always equal 1
#6 date-time fields, pre-filled from 1/1/1990 through 9/30/2023
#15 precipitation fields
#8 temperature fields
#We will replace a subset of the data corresponding to our timeframe of interest
#Whittle the DAT_File to a subset corresponding to our timeframe of interest, "DAT_Shell"----
#Add a Timestep column
DAT_File$TimeStep <- make_date(year = DAT_File$Year,
month = DAT_File$month,
day = DAT_File$day)
View(DAT_File)
Sys.Date()
?floor.date()
#Install and load libraries
library(dplyr)
library(tidyverse)
library(here)
library(lubridate) #for make_date function
?floor_date
Start_Date <- lubridate::floor_date(Sys.Date(), unit = "month")
View(DAT_File)
#Set TimeStep as the 7th column in DAT_Shell
DAT_Shell <- DAT_Shell %>% relocate(TimeStep, .after = s)
#Install and load libraries
library(dplyr)
library(tidyverse)
library(here)
library(lubridate) #for make_date function
#Import DAT stuff
DAT_File <- read.delim(here("InputData/data_update_to_11.30.2022.txt"), sep = "\t")
DAT_Fields <- read.csv(here("InputData/DAT_Fields.csv"))
#Set DAT_File column names
colnames(DAT_File) <- colnames(DAT_Fields)
#Notes about DAT_File fields----
#22 Runoff fields, always equal 1
#6 date-time fields, pre-filled from 1/1/1990 through 9/30/2023
#15 precipitation fields
#8 temperature fields
#We will replace a subset of the data corresponding to our timeframe of interest
#Whittle the DAT_File to a subset corresponding to our timeframe of interest, "DAT_Shell"----
#Add a Timestep column
DAT_File$TimeStep <- make_date(year = DAT_File$Year,
month = DAT_File$month,
day = DAT_File$day)
#Filter to timeframe of interest
#Set the start date by grabbing the first day of the current month
Start_Date <- lubridate::floor_date(Sys.Date(), unit = "month")
#The end date is the current date + 5 days in the future; we grab 6 days of forecast data from CNRFC
End_Date <- Sys.Date() + 5
DAT_Shell <- subset(DAT_File, TimeStep >= '2022-12-01' & TimeStep <= "2023-01-03")
DAT_Shell
#Set TimeStep as the 7th column in DAT_Shell
DAT_Shell <- DAT_Shell %>% relocate(TimeStep, .after = s)
length(Dat_Shell)
length(DAT_Shell)
colnames(DAT_Shell)
i=7
colnames(DAT_Shell)[7]
?str_detect
str_detect(col_names(DAT_Shell)[i],"PREC")
str_detect(colnames(DAT_Shell)[i],"PREC")
str_detect(col_names(DAT_Shell)[8],"PREC")
colnames(DAT_Shell)[8]
str_detect(colnames(DAT_Shell)[8], "PREC")
for (i in 1:length(DAT_Shell)){
if (colnames(DAT_Shell[i]) %>% str_detect("PREC")){
DAT_Shell[i] = ""
} else if (colnames(DAT_Shell[i]) %>% str_detect("TM")){
DAT_Shell[i] = ""
}else {
DAT_Shell[i] = DAT_Shell[i]
}
}
Files = list.files(path = here("WebData"), pattern="*.csv")
for (i in 1:length(Files)) assign(Files[i], read.csv(file = paste0(here("WebData"), "/", Files[i])))
# Set up RSelenium -------------------------------------------------------
## load packages ----
library(RSelenium)
library(tidyverse)
library(netstat)
library(here)
library(dplyr)
library(readr)
CNRFC_Stations <- read.csv("InputData/CNRFC_Stations.csv")
View(CNRFC_Stations)
here()
eCaps <- list(
chromeOptions =
list(prefs = list(
"profile.default_content_settings.popups" = 0L,
"download.prompt_for_download" = FALSE,
"download.default_directory" = gsub(pattern = '/', replacement = '\\\\', x = here("WebData")) # download.dir
)
)
)
default_folder <- eCaps$chromeOptions$prefs$download.default_directory
rs_driver_object <-rsDriver(
browser = 'chrome',
chromever ='108.0.5359.71',
port = free_port(),
extraCapabilities = eCaps
)
remDr <- rs_driver_object$client
i=1
CNRFC <- paste0("https://www.cnrfc.noaa.gov/temperaturePlots_hc.php?id=", CNRFC_Stations$Stations[i])
remDr$navigate(CNRFC)
View(CNRFC_Stations)
ChartMenu <- remDr$findElement(using = "xpath", "//button[@aria-label = 'View chart menu']")
ChartMenu$clickElement()
CSVDownload <- remDr$findElement(using = "xpath", "//ul//li[contains(., 'CSV')]")
CSVDownload$clickElement()
CNRFC <- paste0("https://www.cnrfc.noaa.gov/temperaturePlots_hc.php?id=", CNRFC_Stations$Stations[i])
remDr$navigate(CNRFC)
#Select Chart Menu
ChartMenu <- remDr$findElement(using = "xpath", "//button[@aria-label = 'View chart menu']")
ChartMenu$clickElement()
#Download as CSV
CSVDownload <- remDr$findElement(using = "xpath", "//ul//li[contains(., 'CSV')]")
CSVDownload$clickElement()
}
CNRFC <- paste0("https://www.cnrfc.noaa.gov/temperaturePlots_hc.php?id=", CNRFC_Stations$Stations[i])
remDr$navigate(CNRFC)
#Select Chart Menu
ChartMenu <- remDr$findElement(using = "xpath", "//button[@aria-label = 'View chart menu']")
ChartMenu$clickElement()
#Download as CSV
CSVDownload <- remDr$findElement(using = "xpath", "//ul//li[contains(., 'CSV')]")
CSVDownload$clickElement()
for (i in 1:nrow(CNRFC_Stations)){
CNRFC <- paste0("https://www.cnrfc.noaa.gov/temperaturePlots_hc.php?id=", CNRFC_Stations$Stations[i])
remDr$navigate(CNRFC)
#Select Chart Menu
ChartMenu <- remDr$findElement(using = "xpath", "//button[@aria-label = 'View chart menu']")
ChartMenu$clickElement()
#Download as CSV
CSVDownload <- remDr$findElement(using = "xpath", "//ul//li[contains(., 'CSV')]")
CSVDownload$clickElement()
}
#Install and load libraries
library(dplyr)
library(tidyverse)
library(here)
library(lubridate) #for make_date function
#Import DAT stuff
DAT_File <- read.delim(here("InputData/data_update_to_11.30.2022.txt"), sep = "\t")
DAT_Fields <- read.csv(here("InputData/DAT_Fields.csv"))
#Set DAT_File column names
colnames(DAT_File) <- colnames(DAT_Fields)
#Notes about DAT_File fields----
#22 Runoff fields, always equal 1
#6 date-time fields, pre-filled from 1/1/1990 through 9/30/2023
#15 precipitation fields
#8 temperature fields
#We will replace a subset of the data corresponding to our timeframe of interest
#Whittle the DAT_File to a subset corresponding to our timeframe of interest, "DAT_Shell"----
#Add a Timestep column
DAT_File$TimeStep <- make_date(year = DAT_File$Year,
month = DAT_File$month,
day = DAT_File$day)
#Filter to timeframe of interest
#Set the start date by grabbing the first day of the current month
Start_Date <- lubridate::floor_date(Sys.Date(), unit = "month")
#The end date is the current date + 5 days in the future; we grab 6 days of forecast data from CNRFC
End_Date <- Sys.Date() + 5
DAT_Shell <- subset(DAT_File, TimeStep >= '2022-12-01' & TimeStep <= "2023-01-02")
DAT_Shell
#Set TimeStep as the 7th column in DAT_Shell
DAT_Shell <- DAT_Shell %>% relocate(TimeStep, .after = s)
#Set all the DAT_Shell temperature and precipitation fields to blank
for (i in 1:length(DAT_Shell)){
if (colnames(DAT_Shell[i]) %>% str_detect("PREC")){
DAT_Shell[i] = ""
} else if (colnames(DAT_Shell[i]) %>% str_detect("TM")){
DAT_Shell[i] = ""
}else {
DAT_Shell[i] = DAT_Shell[[i]]
}
}
#Import Observed and Forecast Data----
Files = list.files(path = here("WebData"), pattern="*.csv")
for (i in 1:length(Files)) assign(Files[i], read.csv(file = paste0(here("WebData"), "/", Files[i])))
#Replace Missing Values with PRISM Data----
#RAWS
#CIMIS
#DOWNSIZER
#Set DAT_SHELL from Start_Date to Sys_Date-1 values----
#Filling in all Temp and Precipitation fields
DAT_Shell$PRECIP7 <- PRECIP7.csv$Precipitation
View(DAT_Shell)
usethis::use_git()
install.packages("usethis")
library(usethis)
usethis::use_git()
